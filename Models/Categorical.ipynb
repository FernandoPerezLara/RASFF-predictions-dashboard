{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Categorical embedding"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow as tf\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from sklearn.preprocessing import OneHotEncoder\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, plot_confusion_matrix\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from keras import metrics\r\n",
    "from keras.models import Model\r\n",
    "from keras.layers import Dense, Dropout, Input, Embedding,Reshape, Concatenate"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = pd.read_csv(\"../splited_full_RASFF_DATA.csv\", sep=\";\", header=0, index_col=0)\r\n",
    "data = data.sample(frac=1)\r\n",
    "\r\n",
    "data.head(5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Basic pre-processing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Initial length:\", len(data))\r\n",
    "\r\n",
    "data.HAZARDS_CAT = data.HAZARDS_CAT.astype(str)\r\n",
    "data.DATE_CASE = data.DATE_CASE.astype(str)\r\n",
    "data.DATE_CASE = pd.to_datetime(data.DATE_CASE, errors=\"coerce\")\r\n",
    "data.DATE_CASE = data.DATE_CASE.dt.month\r\n",
    "\r\n",
    "data.dropna(subset=[\"DATE_CASE\"], inplace=True)\r\n",
    "\r\n",
    "print(\"Final length:\", len(data))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Features selection"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "categorical_vars = [0, 1, 6, 8]\r\n",
    "target_vars = [2]\r\n",
    "\r\n",
    "X = data.iloc[:, categorical_vars]\r\n",
    "Y = data.iloc[:, target_vars]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ency = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\r\n",
    "\r\n",
    "ency.fit(Y.values)\r\n",
    "\r\n",
    "y_one_hot = ency.transform(Y.values)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split train-val-test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x_training_data, x_test_data, y_training_data, y_test_data = train_test_split(X, y_one_hot, test_size=0.2, random_state=42, shuffle=True)\r\n",
    "x_training_data, x_val_data, y_training_data, y_val_data = train_test_split(x_training_data, y_training_data, test_size=0.2, random_state=42, shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Coding and conversion to lists for beign able to introduce it into the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "categorical_vars = data.iloc[:, categorical_vars].columns\r\n",
    "\r\n",
    "def preproc(X_train, X_test, X_val):\r\n",
    "    input_list_train = []\r\n",
    "    input_list_test = []\r\n",
    "    input_list_testval = []\r\n",
    "    \r\n",
    "    for c in categorical_vars:\r\n",
    "        raw_vals = np.unique(X_train[c])\r\n",
    "        val_map = {}\r\n",
    "        for i in range(len(raw_vals)):\r\n",
    "            val_map[raw_vals[i]] = i       \r\n",
    "        \r\n",
    "        input_list_train.append(X_train[c].map(val_map).values)\r\n",
    "        input_list_test.append(X_test[c].map(val_map).fillna(0).values)\r\n",
    "        input_list_testval.append(X_val[c].map(val_map).fillna(0).values)\r\n",
    "\r\n",
    "    return input_list_train, input_list_test,input_list_testval"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "input_list_train, input_list_test, input_list_testval = preproc(x_training_data, x_test_data, x_val_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Metrics definition"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def top_1_categorical_accuracy(y_true, y_pred):\r\n",
    "\treturn metrics.top_k_categorical_accuracy(y_true, y_pred, k=1)\r\n",
    "\r\n",
    "def top_2_categorical_accuracy(y_true, y_pred):\r\n",
    "    return metrics.top_k_categorical_accuracy(y_true, y_pred, k=2)\r\n",
    "\r\n",
    "def top_3_categorical_accuracy(y_true, y_pred):\r\n",
    "    return metrics.top_k_categorical_accuracy(y_true, y_pred, k=3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Embeddings + MLP Models (cases 1 and 3)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "input_models = []\r\n",
    "output_embeddings = []\r\n",
    "\r\n",
    "for categorical_var in categorical_vars:\r\n",
    "    cat_emb_name = categorical_var.replace(\" \", \"\") + \"_Embedding\"\r\n",
    "    input_name = \"Input_\" + categorical_var.replace(\" \", \"\")\r\n",
    "    no_of_unique_cat = x_training_data[categorical_var].nunique()\r\n",
    "    embedding_size = int(min(np.ceil((no_of_unique_cat)/2), 50))\r\n",
    "   \r\n",
    "    input_model = Input(shape=(1, ), name=input_name)\r\n",
    "    output_model = Embedding(no_of_unique_cat, embedding_size, name=cat_emb_name)(input_model)\r\n",
    "    output_model = Reshape(target_shape=(embedding_size, ))(output_model)    \r\n",
    "    \r\n",
    "    input_models.append(input_model)\r\n",
    "    output_embeddings.append(output_model)\r\n",
    "  \r\n",
    "output = Concatenate()(output_embeddings)\r\n",
    "output = Dense(2048,activation=\"relu\")(output)\r\n",
    "output = Dropout(0.3)(output)\r\n",
    "output = Dense(1024,activation=\"relu\")(output)\r\n",
    "output = Dropout(0.2)(output)\r\n",
    "output = Dense(512,activation=\"relu\")(output)\r\n",
    "output = Dropout(0.2)(output)\r\n",
    "output = Dense(42, activation=\"softmax\")(output)\r\n",
    "\r\n",
    "model = Model(inputs=input_models, outputs=output)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\", top_1_categorical_accuracy,top_2_categorical_accuracy,top_3_categorical_accuracy])\r\n",
    "\r\n",
    "model.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# REVIEW: No validation data has been provided\r\n",
    " \r\n",
    "# hist = model.fit(input_list_train, y_training_data, validation_data=(input_list_test, y_test_data), epochs=5 , batch_size=64, verbose=1)\r\n",
    "hist = model.fit(input_list_train, y_training_data, validation_data=(input_list_testval, y_val_data), epochs=5, batch_size=64, verbose=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_metrics():\r\n",
    "\tresult = model.predict(input_list_test, batch_size=64)\r\n",
    "\tresult = np.argmax(result, axis=-1)\r\n",
    "\r\n",
    "\tvalid_loss, valid_accuracy, acc1, acc2, acc3 = model.evaluate(input_list_test)\r\n",
    "\r\n",
    "\tprint(\"Loss:\", valid_loss)\r\n",
    "\tprint(\"Accuracy:\", valid_accuracy)\r\n",
    "\tprint(\"Top-1 Accuracy:\", acc1)\r\n",
    "\tprint(\"Top-2 Accuracy:\", acc2)\r\n",
    "\tprint(\"Top-3 Accuracy:\", acc3)\r\n",
    "\r\n",
    "\tprint(classification_report(np.argmax(y_test_data, axis=-1), result, zero_division=True))\r\n",
    "\r\n",
    "\tcm = confusion_matrix(np.argmax(y_test_data, axis=-1), result)\r\n",
    "\tcm = ConfusionMatrixDisplay(confusion_matrix=cm)\r\n",
    "\r\n",
    "\tfig, ax = plt.subplots(figsize=(20, 20))\r\n",
    "\tcm.plot(ax=ax)\r\n",
    "\r\n",
    "\tplt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "get_metrics()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# result = model.predict(input_list_test, batch_size=64)\r\n",
    "# result = np.argmax(result, axis=1)\r\n",
    "\r\n",
    "# valid_loss, valid_accuracy, acc1, acc2, acc3 = model.evaluate(input_list_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# print(\"Loss:\", valid_loss)\r\n",
    "# print(\"Accuracy:\", valid_accuracy)\r\n",
    "# print(\"Top-1 Accuracy:\", acc1)\r\n",
    "# print(\"Top-2 Accuracy:\", acc2)\r\n",
    "# print(\"Top-3 Accuracy:\", acc3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# print(classification_report(np.argmax(y_test_data, axis=-1), result, zero_division=True))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# cm = confusion_matrix(np.argmax(y_test_data, axis=-1), result)\r\n",
    "# cm = ConfusionMatrixDisplay(confusion_matrix=cm)\r\n",
    "\r\n",
    "# fig, ax = plt.subplots(figsize=(20, 20))\r\n",
    "# cm.plot(ax=ax)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "N = 5\r\n",
    "\r\n",
    "plt.style.use(\"ggplot\")\r\n",
    "\r\n",
    "plt.figure()\r\n",
    "\r\n",
    "plt.plot(np.arange(0, N), hist.history[\"loss\"], label=\"train_loss\")\r\n",
    "plt.plot(np.arange(0, N), hist.history[\"val_loss\"], label=\"val_loss\")\r\n",
    "plt.plot(np.arange(0, N), hist.history[\"accuracy\"], label=\"train_acc\")\r\n",
    "plt.plot(np.arange(0, N), hist.history[\"val_accuracy\"], label=\"val_acc\")\r\n",
    "\r\n",
    "plt.title(\"Training Loss and Accuracy\")\r\n",
    "plt.xlabel(\"Epoch #\")\r\n",
    "plt.ylabel(\"Loss/Accuracy\")\r\n",
    "plt.legend(loc=\"lower left\")\r\n",
    "\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "historials = []\r\n",
    "evaluations = []\r\n",
    "\r\n",
    "for i in range (1, 6):\r\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\", top_1_categorical_accuracy, top_2_categorical_accuracy, top_3_categorical_accuracy])\r\n",
    "    \r\n",
    "    hist = model.fit(input_list_train, y_training_data, validation_data=(input_list_testval, y_val_data), epochs=25, batch_size=64, verbose=0)\r\n",
    "    historials.append(hist)\r\n",
    "    \r\n",
    "    evaluation = model.evaluate(x=input_list_test, y=y_test_data)\r\n",
    "    evaluations.append(evaluation)\r\n",
    "    \r\n",
    "    model.save(\"model\" + str(i) + \".h5\")\r\n",
    "\r\n",
    "    get_metrics()\r\n",
    "\r\n",
    "    print(\"\\n\\n-----------------------\\n\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('ceiec': conda)"
  },
  "interpreter": {
   "hash": "d98ed641ffb0afae769cd9f96943c7d5fe6ff4d949b5ee86e4a8c8a547fca37e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}