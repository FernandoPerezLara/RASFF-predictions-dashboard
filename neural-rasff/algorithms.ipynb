{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Non-neural models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "from sklearn import tree\r\n",
    "from sklearn.feature_extraction import FeatureHasher\r\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV \r\n",
    "from sklearn.ensemble import GradientBoostingClassifier,AdaBoostClassifier, RandomForestClassifier\r\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, MultiLabelBinarizer\r\n",
    "from sklearn.metrics import classification_report, accuracy_score, recall_score, precision_score, confusion_matrix, ConfusionMatrixDisplay\r\n",
    "from itertools import chain\r\n",
    "from sklearn.linear_model import LogisticRegression"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Code"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "data = pd.read_csv(\"./data/full_RASFF_DATA.csv\", sep=\";\", header=0, index_col=0)\r\n",
    "\r\n",
    "data.head(3)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLASSIF</th>\n",
       "      <th>DATE_CASE</th>\n",
       "      <th>REF</th>\n",
       "      <th>NOT_COUNTRY</th>\n",
       "      <th>SUBJET</th>\n",
       "      <th>PROD_CAT</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>RISK_DECISION</th>\n",
       "      <th>ACTION_TAKEN</th>\n",
       "      <th>DISTRIBUTION_STAT</th>\n",
       "      <th>PRODUCT</th>\n",
       "      <th>HAZARDS</th>\n",
       "      <th>HAZARDS_CAT</th>\n",
       "      <th>COUNT_ORIGEN</th>\n",
       "      <th>COUNT_DESTIN</th>\n",
       "      <th>COUNT_CONCERN</th>\n",
       "      <th>NUMBER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alert</td>\n",
       "      <td>2020-10-16</td>\n",
       "      <td>2020.4364</td>\n",
       "      <td>France</td>\n",
       "      <td>Listeria monocytogenes (presence) in ham trimm...</td>\n",
       "      <td>meat and meat products (other than poultry)</td>\n",
       "      <td>food</td>\n",
       "      <td>serious</td>\n",
       "      <td>recall from consumers</td>\n",
       "      <td>distribution to other member countries</td>\n",
       "      <td>ham trimmings</td>\n",
       "      <td>listeria monocytogenes</td>\n",
       "      <td>microbial contaminants (other)</td>\n",
       "      <td>France</td>\n",
       "      <td>Czech Republic,United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>border rejection</td>\n",
       "      <td>2020-10-16</td>\n",
       "      <td>2020.4349</td>\n",
       "      <td>Bulgaria</td>\n",
       "      <td>prochloraz (0.696 mg/kg - ppm) in mandarins fr...</td>\n",
       "      <td>fruits and vegetables</td>\n",
       "      <td>food</td>\n",
       "      <td>serious</td>\n",
       "      <td>destruction</td>\n",
       "      <td>product not (yet) placed on the market</td>\n",
       "      <td>mandarins</td>\n",
       "      <td>prochloraz</td>\n",
       "      <td>pesticide residues</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bulgaria</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>border rejection</td>\n",
       "      <td>2020-10-16</td>\n",
       "      <td>2020.4350</td>\n",
       "      <td>Bulgaria</td>\n",
       "      <td>fenvalerate (0.357 mg/kg - ppm) in chilled man...</td>\n",
       "      <td>fruits and vegetables</td>\n",
       "      <td>food</td>\n",
       "      <td>serious</td>\n",
       "      <td>re-dispatch</td>\n",
       "      <td>product not (yet) placed on the market</td>\n",
       "      <td>chilled mandarins</td>\n",
       "      <td>fenvalerate</td>\n",
       "      <td>pesticide residues</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bulgaria</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            CLASSIF   DATE_CASE        REF NOT_COUNTRY  \\\n",
       "0             alert  2020-10-16  2020.4364      France   \n",
       "1  border rejection  2020-10-16  2020.4349    Bulgaria   \n",
       "2  border rejection  2020-10-16  2020.4350    Bulgaria   \n",
       "\n",
       "                                              SUBJET  \\\n",
       "0  Listeria monocytogenes (presence) in ham trimm...   \n",
       "1  prochloraz (0.696 mg/kg - ppm) in mandarins fr...   \n",
       "2  fenvalerate (0.357 mg/kg - ppm) in chilled man...   \n",
       "\n",
       "                                      PROD_CAT  TYPE RISK_DECISION  \\\n",
       "0  meat and meat products (other than poultry)  food       serious   \n",
       "1                        fruits and vegetables  food       serious   \n",
       "2                        fruits and vegetables  food       serious   \n",
       "\n",
       "            ACTION_TAKEN                       DISTRIBUTION_STAT  \\\n",
       "0  recall from consumers  distribution to other member countries   \n",
       "1            destruction  product not (yet) placed on the market   \n",
       "2            re-dispatch  product not (yet) placed on the market   \n",
       "\n",
       "             PRODUCT                 HAZARDS                     HAZARDS_CAT  \\\n",
       "0      ham trimmings  listeria monocytogenes  microbial contaminants (other)   \n",
       "1          mandarins              prochloraz              pesticide residues   \n",
       "2  chilled mandarins             fenvalerate              pesticide residues   \n",
       "\n",
       "  COUNT_ORIGEN                   COUNT_DESTIN COUNT_CONCERN  NUMBER  \n",
       "0       France  Czech Republic,United Kingdom           NaN     NaN  \n",
       "1       Turkey                            NaN      Bulgaria     NaN  \n",
       "2       Turkey                            NaN      Bulgaria     NaN  "
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class Stage:\r\n",
    "\tdef __init__(self, input, output):\r\n",
    "\t\tself.input = input\r\n",
    "\t\tself.output = output\r\n",
    "\r\n",
    "\t\tself.x = data.iloc[:, input]\r\n",
    "\t\tself.y = data.iloc[:, output]\r\n",
    "\r\n",
    "\t\tself.x_train, self.x_test, self.y_train, self.y_test = None, None, None, None\r\n",
    "\r\n",
    "\t\tself.classifier = self.Classifier()\r\n",
    "\t\t\r\n",
    "\t\tself.__transform()\r\n",
    "\r\n",
    "\tdef __transform(self):\r\n",
    "\t\ttrain_mask = (data.DATE_CASE >= \"2004-01-01\") & (data.DATE_CASE <= \"2018-12-31\")\r\n",
    "\t\ttest_mask = (data.DATE_CASE >= \"2019-01-01\") & (data.DATE_CASE <= \"2019-12-31\")\r\n",
    "\r\n",
    "\t\tstrategy = OneHotEncoder(handle_unknown=\"ignore\") # One Hot Encoder\r\n",
    "\t\t# strategy = OrdinalEncoder() # Integer\r\n",
    "\t\t# strategy = FeatureHasher(n_features=25, input_type=\"string\") # Hashing\r\n",
    "\t\t# strategy = MultiLabelBinarizer() # Binary\r\n",
    "\r\n",
    "\t\tstrategy.fit(self.x.values)\r\n",
    "\r\n",
    "\t\tself.x_train = self.x.loc[train_mask]\r\n",
    "\t\tself.y_train = self.y.loc[train_mask]\r\n",
    "\r\n",
    "\t\tself.x_test = self.x.loc[test_mask]\r\n",
    "\t\tself.y_test = self.y.loc[test_mask]\r\n",
    "\r\n",
    "\t\tprint(self.x_train.shape, self.y_train.shape)\r\n",
    "\t\tprint(self.x_test.shape, self.y_test.shape)\r\n",
    "\t\t\r\n",
    "\t\tself.x_train = strategy.transform(self.x_train.values)\r\n",
    "\t\tself.x_test = strategy.transform(self.x_test.values)\r\n",
    "\r\n",
    "\t\t# self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(strategy.transform(self.x.values), self.y, test_size=0.2)\r\n",
    "\r\n",
    "\tclass Classifier:\r\n",
    "\t\tpass"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def get_specifity(y_actual, y_pred):\r\n",
    "    TN = []\r\n",
    "    FP = []\r\n",
    "\r\n",
    "    for index ,_id in enumerate(np.union1d(y_actual, y_pred)):\r\n",
    "        FP.append(0)\r\n",
    "        TN.append(0)\r\n",
    "\r\n",
    "        for i in range(len(y_pred)):\r\n",
    "            if y_pred[i] == _id and y_actual[i] != y_pred[i]:\r\n",
    "                FP[index] += 1\r\n",
    "            if y_actual[i] == y_pred[i] != _id:\r\n",
    "                TN[index] += 1\r\n",
    "\r\n",
    "    TN = sum(TN)\r\n",
    "    FP = sum(FP)\r\n",
    "\r\n",
    "    return TN/(TN + FP)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "data.DATE_CASE = data.DATE_CASE.astype(str)\r\n",
    "data.HAZARDS_CAT = data.HAZARDS_CAT.astype(str)\r\n",
    "data.COUNT_DESTIN = data.COUNT_DESTIN.astype(str)\r\n",
    "data.COUNT_CONCERN = data.COUNT_CONCERN.astype(str)\r\n",
    "\r\n",
    "data.dropna(subset=data.columns[[1, 3, 5, 8, 9, 12, 13]], inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "data = data.sample(frac=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transformation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def chainer(s):\r\n",
    "    return list(chain.from_iterable(s.str.split(',')))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "lens = data['HAZARDS_CAT'].str.split(',').map(len)\r\n",
    "split1 = pd.DataFrame({'DATE_CASE': np.repeat(data['DATE_CASE'], lens),\r\n",
    "                    'NOT_COUNTRY': np.repeat(data['NOT_COUNTRY'], lens),\r\n",
    "                    'PROD_CAT': np.repeat(data['PROD_CAT'], lens),\r\n",
    "                    'TYPE': np.repeat(data['TYPE'], lens),\r\n",
    "                    'RISK_DECISION': np.repeat(data['RISK_DECISION'], lens),\r\n",
    "                    'ACTION_TAKEN': np.repeat(data['ACTION_TAKEN'], lens),\r\n",
    "                    'DISTRIBUTION_STAT': np.repeat(data['DISTRIBUTION_STAT'], lens),\r\n",
    "                    'HAZARDS_CAT': chainer(data['HAZARDS_CAT']),\r\n",
    "                    'COUNT_ORIGEN': np.repeat(data['COUNT_ORIGEN'], lens),\r\n",
    "                    'COUNT_DESTIN': np.repeat(data['COUNT_DESTIN'], lens),\r\n",
    "                    'COUNT_CONCERN': np.repeat(data['COUNT_CONCERN'], lens)})\r\n",
    "\r\n",
    "lens = split1['COUNT_ORIGEN'].str.split(',').map(len)\r\n",
    "split2 = pd.DataFrame({'DATE_CASE': np.repeat(split1['DATE_CASE'], lens),\r\n",
    "                    'NOT_COUNTRY': np.repeat(split1['NOT_COUNTRY'], lens),\r\n",
    "                    'PROD_CAT': np.repeat(split1['PROD_CAT'], lens),\r\n",
    "                    'TYPE': np.repeat(split1['TYPE'], lens),\r\n",
    "                    'RISK_DECISION': np.repeat(split1['RISK_DECISION'], lens),\r\n",
    "                    'ACTION_TAKEN': np.repeat(split1['ACTION_TAKEN'], lens),\r\n",
    "                    'DISTRIBUTION_STAT': np.repeat(split1['DISTRIBUTION_STAT'], lens),\r\n",
    "                    'HAZARDS_CAT': np.repeat(split1['HAZARDS_CAT'], lens),\r\n",
    "                    'COUNT_ORIGEN': chainer(split1['COUNT_ORIGEN']),\r\n",
    "                    'COUNT_DESTIN': np.repeat(split1['COUNT_DESTIN'], lens),\r\n",
    "                    'COUNT_CONCERN': np.repeat(split1['COUNT_CONCERN'], lens)})\r\n",
    "\r\n",
    "lens = split2['COUNT_DESTIN'].str.split(',').map(len)\r\n",
    "split3 = pd.DataFrame({'DATE_CASE': np.repeat(split2['DATE_CASE'], lens),\r\n",
    "                    'NOT_COUNTRY': np.repeat(split2['NOT_COUNTRY'], lens),\r\n",
    "                    'PROD_CAT': np.repeat(split2['PROD_CAT'], lens),\r\n",
    "                    'TYPE': np.repeat(split2['TYPE'], lens),\r\n",
    "                    'RISK_DECISION': np.repeat(split2['RISK_DECISION'], lens),\r\n",
    "                    'ACTION_TAKEN': np.repeat(split2['ACTION_TAKEN'], lens),\r\n",
    "                    'DISTRIBUTION_STAT': np.repeat(split2['DISTRIBUTION_STAT'], lens),\r\n",
    "                    'HAZARDS_CAT': np.repeat(split2['HAZARDS_CAT'], lens),\r\n",
    "                    'COUNT_ORIGEN': np.repeat(split2['COUNT_ORIGEN'], lens),\r\n",
    "                    'COUNT_DESTIN': chainer(split2['COUNT_DESTIN']),\r\n",
    "                    'COUNT_CONCERN': np.repeat(split2['COUNT_CONCERN'], lens)})\r\n",
    "\r\n",
    "lens = split3['COUNT_CONCERN'].str.split(',').map(len)\r\n",
    "split4 = pd.DataFrame({'DATE_CASE': np.repeat(split3['DATE_CASE'], lens),\r\n",
    "                    'NOT_COUNTRY': np.repeat(split3['NOT_COUNTRY'], lens),\r\n",
    "                    'PROD_CAT': np.repeat(split3['PROD_CAT'], lens),\r\n",
    "                    'TYPE': np.repeat(split3['TYPE'], lens),\r\n",
    "                    'RISK_DECISION': np.repeat(split3['RISK_DECISION'], lens),\r\n",
    "                    'ACTION_TAKEN': np.repeat(split3['ACTION_TAKEN'], lens),\r\n",
    "                    'DISTRIBUTION_STAT': np.repeat(split3['DISTRIBUTION_STAT'], lens),\r\n",
    "                    'HAZARDS_CAT': np.repeat(split3['HAZARDS_CAT'], lens),\r\n",
    "                    'COUNT_ORIGEN': np.repeat(split3['COUNT_ORIGEN'], lens),\r\n",
    "                    'COUNT_DESTIN': np.repeat(split3['COUNT_DESTIN'], lens),\r\n",
    "                    'COUNT_CONCERN': chainer(split3['COUNT_CONCERN'])})\r\n",
    "\r\n",
    "split4 = split4.reset_index(drop = True)\r\n",
    "split4 = split4.dropna(subset = ['DATE_CASE'])\r\n",
    "\r\n",
    "data = split4.copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "data.head(3)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE_CASE</th>\n",
       "      <th>NOT_COUNTRY</th>\n",
       "      <th>PROD_CAT</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>RISK_DECISION</th>\n",
       "      <th>ACTION_TAKEN</th>\n",
       "      <th>DISTRIBUTION_STAT</th>\n",
       "      <th>HAZARDS_CAT</th>\n",
       "      <th>COUNT_ORIGEN</th>\n",
       "      <th>COUNT_DESTIN</th>\n",
       "      <th>COUNT_CONCERN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-09-06</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>feed materials</td>\n",
       "      <td>feed</td>\n",
       "      <td>not serious</td>\n",
       "      <td>physical/chemical treatment</td>\n",
       "      <td>distribution to other member countries</td>\n",
       "      <td>pathogenic micro-organisms</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-09-06</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>feed materials</td>\n",
       "      <td>feed</td>\n",
       "      <td>not serious</td>\n",
       "      <td>physical/chemical treatment</td>\n",
       "      <td>distribution to other member countries</td>\n",
       "      <td>pathogenic micro-organisms</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-09-06</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>feed materials</td>\n",
       "      <td>feed</td>\n",
       "      <td>not serious</td>\n",
       "      <td>physical/chemical treatment</td>\n",
       "      <td>distribution to other member countries</td>\n",
       "      <td>pathogenic micro-organisms</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DATE_CASE NOT_COUNTRY        PROD_CAT  TYPE RISK_DECISION  \\\n",
       "0  2012-09-06     Belgium  feed materials  feed   not serious   \n",
       "1  2012-09-06     Belgium  feed materials  feed   not serious   \n",
       "2  2012-09-06     Belgium  feed materials  feed   not serious   \n",
       "\n",
       "                  ACTION_TAKEN                       DISTRIBUTION_STAT  \\\n",
       "0  physical/chemical treatment  distribution to other member countries   \n",
       "1  physical/chemical treatment  distribution to other member countries   \n",
       "2  physical/chemical treatment  distribution to other member countries   \n",
       "\n",
       "                  HAZARDS_CAT COUNT_ORIGEN    COUNT_DESTIN COUNT_CONCERN  \n",
       "0  pathogenic micro-organisms      Germany         Belgium           nan  \n",
       "1  pathogenic micro-organisms      Germany  Czech Republic           nan  \n",
       "2  pathogenic micro-organisms      Germany         Denmark           nan  "
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "stage1 = Stage(\r\n",
    "\t# input=[0, 1, 6, 8],\r\n",
    "\t# input=[1, 3, 9, 13],\r\n",
    "\t# output=[5] # Product category\r\n",
    "\t\r\n",
    "\tinput=[0, 1, 6, 8],\r\n",
    "\toutput=[2]\r\n",
    ")\r\n",
    "\r\n",
    "stage2 = Stage(\r\n",
    "\t# input=[0, 1, 2, 6, 8],\r\n",
    "\t# input=[1, 3, 9, 13, 5],\r\n",
    "\t# output=[12] # Hazard category\r\n",
    "\t\r\n",
    "\tinput=[0, 1, 6, 8, 2],\r\n",
    "\toutput=[7]\r\n",
    ")\r\n",
    "\r\n",
    "stage3 = Stage(\r\n",
    "\t# input=[0, 1, 2, 6, 7, 8],\r\n",
    "\t# input=[1, 3, 9, 13, 5, 12],\r\n",
    "\t# output=[8] # Decision taken\r\n",
    "\t\r\n",
    "\tinput=[0, 1, 6, 8, 2, 7],\r\n",
    "\toutput=[5]\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(131712, 4) (131712, 1)\n",
      "(15055, 4) (15055, 1)\n",
      "(131712, 5) (131712, 1)\n",
      "(15055, 5) (15055, 1)\n",
      "(131712, 6) (131712, 1)\n",
      "(15055, 6) (15055, 1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data mining"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decision trees"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class DecisionTree:\r\n",
    "\tdef __init__(self, stage, params):\r\n",
    "\t\tself.stage = stage\r\n",
    "\t\tself.params = params\r\n",
    "\r\n",
    "\t\tself.classifier = GridSearchCV(tree.DecisionTreeClassifier(random_state=42), self.params, cv=3)\r\n",
    "\t\tself.classifier.fit(stage.x_train, stage.y_train)\r\n",
    "\r\n",
    "\t\tself.best_params = self.classifier.best_params_\r\n",
    "\r\n",
    "\t\tself.classifier = tree.DecisionTreeClassifier(**self.best_params, random_state=42)\r\n",
    "\t\tself.classifier.fit(stage.x_train, stage.y_train)\r\n",
    "\r\n",
    "\t\tself.y_predict = None\r\n",
    "\r\n",
    "\tdef predict(self):\r\n",
    "\t\tself.y_predict = self.classifier.predict(self.stage.x_test)\r\n",
    "\r\n",
    "\tdef get_metrics(self):\r\n",
    "\t\tprint(f\"- Accuracy: {round(accuracy_score(self.stage.y_test, self.y_predict)*100, 2)}%\")\r\n",
    "\t\tprint(f\"- Specifity: {round(get_specifity(self.stage.y_test.values, self.y_predict)*100, 2)}%\")\r\n",
    "\t\tprint(f\"- Sensitivity: {round(recall_score(self.stage.y_test, self.y_predict, average='macro', zero_division=0)*100, 2)}%\")\r\n",
    "\t\tprint(f\"- Precision: {round(precision_score(self.stage.y_test, self.y_predict, average='macro', zero_division=0)*100, 2)}%\")\r\n",
    "\t\t\r\n",
    "\t\tprint(classification_report(self.stage.y_test, self.y_predict, zero_division=0))\r\n",
    "\r\n",
    "\t\tcm = confusion_matrix(self.stage.y_test, self.y_predict)\r\n",
    "\t\tcm = ConfusionMatrixDisplay(confusion_matrix=cm)\r\n",
    "\r\n",
    "\t\t_, ax = plt.subplots(figsize=(10, 10))\r\n",
    "\t\tcm.plot(ax=ax)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "params = {\r\n",
    "\t\"criterion\": [\"gini\", \"entropy\"],\r\n",
    "\t\"splitter\": [\"best\", \"random\"],\r\n",
    "\t\"max_features\": [\"auto\", \"sqrt\", \"log2\"]\r\n",
    "}\r\n",
    "\r\n",
    "stage1.classifier.decision_tree = DecisionTree(stage1, params)\r\n",
    "print(f\"Stage 1 completed: {stage1.classifier.decision_tree.best_params}\")\r\n",
    "\r\n",
    "stage2.classifier.decision_tree = DecisionTree(stage2, params)\r\n",
    "print(f\"Stage 2 completed: {stage2.classifier.decision_tree.best_params}\")\r\n",
    "\r\n",
    "stage3.classifier.decision_tree = DecisionTree(stage3, params)\r\n",
    "print(f\"Stage 3 completed: {stage3.classifier.decision_tree.best_params}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "stage1.classifier.decision_tree.predict()\r\n",
    "stage2.classifier.decision_tree.predict()\r\n",
    "stage3.classifier.decision_tree.predict()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Stage 1\")\r\n",
    "stage1.classifier.decision_tree.get_metrics()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Stage 2\")\r\n",
    "stage2.classifier.decision_tree.get_metrics()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Stage 3\")\r\n",
    "stage3.classifier.decision_tree.get_metrics()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Boosted trees"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class BoostedTrees:\r\n",
    "\tdef __init__(self, stage, params):\r\n",
    "\t\tself.stage = stage\r\n",
    "\t\tself.params = params\r\n",
    "\t\t\r\n",
    "\t\tself.classifier = GridSearchCV(GradientBoostingClassifier(max_features=\"sqrt\", subsample=0.8, random_state=10), self.params, n_jobs=4, cv=3)\r\n",
    "\t\tself.classifier.fit(stage.x_train, stage.y_train.values.ravel())\r\n",
    "\r\n",
    "\t\tself.best_params = self.classifier.best_params_\r\n",
    "\r\n",
    "\t\tself.classifier = GradientBoostingClassifier(**self.best_params, max_features=\"sqrt\", subsample=0.8, random_state=10)\r\n",
    "\t\tself.classifier.fit(stage.x_train, stage.y_train.values.ravel())\r\n",
    "\r\n",
    "\t\tself.y_predict = None\r\n",
    "\r\n",
    "\tdef predict(self):\r\n",
    "\t\tself.y_predict = self.classifier.predict(self.stage.x_test)\r\n",
    "\r\n",
    "\tdef get_metrics(self):\r\n",
    "\t\tprint(f\"- Accuracy: {round(accuracy_score(self.stage.y_test, self.y_predict)*100, 2)}%\")\r\n",
    "\t\tprint(f\"- Specifity: {round(get_specifity(self.stage.y_test.values, self.y_predict)*100, 2)}%\")\r\n",
    "\t\tprint(f\"- Sensitivity: {round(recall_score(self.stage.y_test, self.y_predict, average='macro', zero_division=0)*100, 2)}%\")\r\n",
    "\t\tprint(f\"- Precission: {round(precision_score(self.stage.y_test, self.y_predict, average='macro', zero_division=0)*100, 2)}%\")\r\n",
    "\t\t\r\n",
    "\t\tprint(classification_report(self.stage.y_test, self.y_predict, zero_division=0))\r\n",
    "\r\n",
    "\t\tcm = confusion_matrix(self.stage.y_test, self.y_predict)\r\n",
    "\t\tcm = ConfusionMatrixDisplay(confusion_matrix=cm)\r\n",
    "\r\n",
    "\t\t_, ax = plt.subplots(figsize=(10, 10))\r\n",
    "\t\tcm.plot(ax=ax)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "params = {\r\n",
    "\t\"n_estimators\": range(20, 51, 10),\r\n",
    "\t\"learning_rate\": [1, 0.1, 0.01],\r\n",
    "\t\"max_depth\": range(5, 10, 2),\r\n",
    "\t\"min_samples_split\": range(200, 601, 200)\r\n",
    "}\r\n",
    "\r\n",
    "stage1.classifier.boosted_trees = BoostedTrees(stage1, params)\r\n",
    "print(f\"Stage 1 completed: {stage1.classifier.boosted_trees.best_params}\")\r\n",
    "\r\n",
    "stage2.classifier.boosted_trees = BoostedTrees(stage2, params)\r\n",
    "print(f\"Stage 2 completed: {stage2.classifier.boosted_trees.best_params}\")\r\n",
    "\r\n",
    "stage3.classifier.boosted_trees = BoostedTrees(stage3, params)\r\n",
    "print(f\"Stage 3 completed: {stage3.classifier.boosted_trees.best_params}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "stage1.classifier.boosted_trees.predict()\r\n",
    "stage2.classifier.boosted_trees.predict()\r\n",
    "stage3.classifier.boosted_trees.predict()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Stage 1\")\r\n",
    "stage1.classifier.boosted_trees.get_metrics()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Stage 2\")\r\n",
    "stage2.classifier.boosted_trees.get_metrics()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Stage 3\")\r\n",
    "stage3.classifier.boosted_trees.get_metrics()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random Forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "class RandomForest:\r\n",
    "\tdef __init__(self, stage,params):\r\n",
    "\t\tself.stage = stage\r\n",
    "\t\tself.params=params\r\n",
    "\t\t\r\n",
    "\r\n",
    "\t\trf = RandomForestClassifier()\r\n",
    "\r\n",
    "\r\n",
    "\t\tself.classifier = GridSearchCV(estimator = rf, param_grid = self.params, \r\n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\r\n",
    "\t\tself.classifier.fit(stage.x_train, stage.y_train)\r\n",
    "\r\n",
    "\t\tself.best_params = self.classifier.best_params_\r\n",
    "\r\n",
    "\t\tself.classifier = RandomForestClassifier(**self.best_params)\r\n",
    "\t\tself.classifier.fit(stage.x_train, stage.y_train)\r\n",
    "\r\n",
    "\t\tself.y_predict = None\r\n",
    "\r\n",
    "\tdef predict(self):\r\n",
    "\t\tself.y_predict = self.classifier.predict(self.stage.x_test)\r\n",
    "\r\n",
    "\tdef get_metrics(self):\r\n",
    "\t\tprint(f\"- Accuracy: {round(accuracy_score(self.stage.y_test, self.y_predict)*100, 2)}%\")\r\n",
    "\t\tprint(f\"- Specifity: {round(get_specifity(self.stage.y_test.values, self.y_predict)*100, 2)}%\")\r\n",
    "\t\tprint(f\"- Sensitivity: {round(recall_score(self.stage.y_test, self.y_predict, average='macro', zero_division=0)*100, 2)}%\")\r\n",
    "\t\tprint(f\"- Precision: {round(precision_score(self.stage.y_test, self.y_predict, average='macro', zero_division=0)*100, 2)}%\")\r\n",
    "\t\t\r\n",
    "\t\tprint(classification_report(self.stage.y_test, self.y_predict, zero_division=0))\r\n",
    "\r\n",
    "\t\tcm = confusion_matrix(self.stage.y_test, self.y_predict)\r\n",
    "\t\tcm = ConfusionMatrixDisplay(confusion_matrix=cm)\r\n",
    "\r\n",
    "\t\t_, ax = plt.subplots(figsize=(10, 10))\r\n",
    "\t\tcm.plot(ax=ax)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "params = {\r\n",
    "    'bootstrap': [True],\r\n",
    "    'max_depth': [100, 110],\r\n",
    "    'max_features': [2, 3],\r\n",
    "    'min_samples_leaf': [4, 5],\r\n",
    "    'min_samples_split': [10, 12],\r\n",
    "    'n_estimators': [200, 300, 500]}\r\n",
    "\r\n",
    "stage1.classifier.Random_forest = RandomForest(stage1, params)\r\n",
    "print(f\"Stage 1 completed: {stage1.classifier.Random_forest.best_params}\")\r\n",
    "\r\n",
    "stage2.classifier.Random_forest = RandomForest(stage2, params)\r\n",
    "print(f\"Stage 2 completed: {stage2.classifier.Random_forest.best_params}\")\r\n",
    "\r\n",
    "stage3.classifier.Random_forest = RandomForest(stage3, params)\r\n",
    "print(f\"Stage 3 completed: {stage3.classifier.Random_forest.best_params}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "stage1.classifier.Random_forest.predict()\r\n",
    "stage2.classifier.Random_forest.predict()\r\n",
    "stage3.classifier.Random_forest.predict()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Stage 1\")\r\n",
    "stage1.classifier.Random_forest.get_metrics()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Stage 2\")\r\n",
    "stage2.classifier.Random_forest.get_metrics()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Stage 3\")\r\n",
    "stage3.classifier.Random_forest.get_metrics()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logistic Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class LogisticRegression1:\r\n",
    "\tdef __init__(self, stage, params):\r\n",
    "\t\tself.stage = stage\r\n",
    "\t\tself.params = params\r\n",
    "\r\n",
    "\t\tself.classifier = GridSearchCV(LogisticRegression(), param_grid=self.params, scoring=\"recall\")\r\n",
    "\t\tself.classifier.fit(stage.x_train, stage.y_train)\r\n",
    "\r\n",
    "\t\tself.best_params = self.classifier.best_params_\r\n",
    "\r\n",
    "\t\tself.classifier = LogisticRegression(**self.best_params)\r\n",
    "\t\tself.classifier.fit(stage.x_train, stage.y_train)\r\n",
    "\r\n",
    "\t\tself.y_predict = None\r\n",
    "\r\n",
    "\tdef predict(self):\r\n",
    "\t\tself.y_predict = self.classifier.predict(self.stage.x_test)\r\n",
    "\r\n",
    "\tdef get_metrics(self):\r\n",
    "\t\tprint(f\"- Accuracy: {round(accuracy_score(self.stage.y_test, self.y_predict)*100, 2)}%\")\r\n",
    "\t\tprint(f\"- Specifity: {round(get_specifity(self.stage.y_test.values, self.y_predict)*100, 2)}%\")\r\n",
    "\t\tprint(f\"- Sensitivity: {round(recall_score(self.stage.y_test, self.y_predict, average='macro', zero_division=0)*100, 2)}%\")\r\n",
    "\t\tprint(f\"- Precision: {round(precision_score(self.stage.y_test, self.y_predict, average='macro', zero_division=0)*100, 2)}%\")\r\n",
    "\t\t\r\n",
    "\t\tprint(classification_report(self.stage.y_test, self.y_predict, zero_division=0))\r\n",
    "\r\n",
    "\t\tcm = confusion_matrix(self.stage.y_test, self.y_predict)\r\n",
    "\t\tcm = ConfusionMatrixDisplay(confusion_matrix=cm)\r\n",
    "\r\n",
    "\t\t_, ax = plt.subplots(figsize=(10, 10))\r\n",
    "\t\tcm.plot(ax=ax)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "params = {\r\n",
    "\t\"penalty\": [\"l2\"],\r\n",
    "\t\"C\": [0.001, 0.01, 0.1, 1, 10]\r\n",
    "}\r\n",
    "\r\n",
    "stage1.classifier.Logistic_regression = LogisticRegression1(stage1, params)\r\n",
    "print(f\"Stage 1 completed: {stage1.classifier.Logistic_regression.best_params}\")\r\n",
    "\r\n",
    "stage2.classifier.Logistic_regression = LogisticRegression1(stage2, params)\r\n",
    "print(f\"Stage 2 completed: {stage2.classifier.Logistic_regression.best_params}\")\r\n",
    "\r\n",
    "stage3.classifier.Logistic_regression = LogisticRegression1(stage3, params)\r\n",
    "print(f\"Stage 3 completed: {stage3.classifier.Logistic_regression.best_params}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "stage1.classifier.Random_forest.predict()\r\n",
    "stage2.classifier.Random_forest.predict()\r\n",
    "stage3.classifier.Random_forest.predict()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Stage 1\")\r\n",
    "stage1.classifier.Random_forest.get_metrics()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Stage 2\")\r\n",
    "stage2.classifier.Random_forest.get_metrics()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Stage 3\")\r\n",
    "stage3.classifier.Random_forest.get_metrics()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Support vector machine"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class SupportVectorMachine:\r\n",
    "\tdef __init__(self, stage, params):\r\n",
    "\t\tself.stage = stage\r\n",
    "\t\tself.params = params\r\n",
    "\t\t\r\n",
    "\t\tself.classifier = GridSearchCV(svm.SVC(), self.params, refit=True, verbose=3)\r\n",
    "\t\tself.classifier.fit(stage.x_train, stage.y_train.values.ravel())\r\n",
    "\r\n",
    "\t\tself.best_params = self.classifier.best_params_\r\n",
    "\r\n",
    "\t\tself.classifier = svm.SVC(**self.best_params)\r\n",
    "\t\tself.classifier.fit(stage.x_train, stage.y_train.values.ravel())\r\n",
    "\r\n",
    "\t\tself.y_predict = None\r\n",
    "\r\n",
    "\tdef predict(self):\r\n",
    "\t\tself.y_predict = self.classifier.predict(self.stage.x_test)\r\n",
    "\r\n",
    "\tdef get_metrics(self):\r\n",
    "\t\tprint(f\"- Accuracy: {round(accuracy_score(self.stage.y_test, self.y_predict)*100, 2)}%\")\r\n",
    "\t\tprint(f\"- Specifity: {round(get_specifity(self.stage.y_test.values, self.y_predict)*100, 2)}%\")\r\n",
    "\t\tprint(f\"- Sensitivity: {round(recall_score(self.stage.y_test, self.y_predict, average='macro', zero_division=0)*100, 2)}%\")\r\n",
    "\t\tprint(f\"- Precission: {round(precision_score(self.stage.y_test, self.y_predict, average='macro', zero_division=0)*100, 2)}%\")\r\n",
    "\t\t\r\n",
    "\t\tprint(classification_report(self.stage.y_test, self.y_predict, zero_division=0))\r\n",
    "\r\n",
    "\t\tcm = confusion_matrix(self.stage.y_test, self.y_predict)\r\n",
    "\t\tcm = ConfusionMatrixDisplay(confusion_matrix=cm)\r\n",
    "\r\n",
    "\t\t_, ax = plt.subplots(figsize=(10, 10))\r\n",
    "\t\tcm.plot(ax=ax)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "params = {\r\n",
    "\t\"C\": [0.1, 1, 10], \r\n",
    "    \"gamma\": [1, 0.1, 0.01],\r\n",
    "    \"kernel\": [\"rbf\"]\r\n",
    "} \r\n",
    "\r\n",
    "stage1.classifier.support_vector_machine = SupportVectorMachine(stage1, params)\r\n",
    "print(f\"Stage 1 completed: {stage1.classifier.support_vector_machine.best_params}\")\r\n",
    "\r\n",
    "stage2.classifier.support_vector_machine = SupportVectorMachine(stage2, params)\r\n",
    "print(f\"Stage 2 completed: {stage2.classifier.support_vector_machine.best_params}\")\r\n",
    "\r\n",
    "stage3.classifier.support_vector_machine = SupportVectorMachine(stage3, params)\r\n",
    "print(f\"Stage 3 completed: {stage3.classifier.support_vector_machine.best_params}\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('ceiec': conda)"
  },
  "interpreter": {
   "hash": "d98ed641ffb0afae769cd9f96943c7d5fe6ff4d949b5ee86e4a8c8a547fca37e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}