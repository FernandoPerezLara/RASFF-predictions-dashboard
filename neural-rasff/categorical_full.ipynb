{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.8.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.11 64-bit ('ceiec': conda)"
    },
    "interpreter": {
      "hash": "d98ed641ffb0afae769cd9f96943c7d5fe6ff4d949b5ee86e4a8c8a547fca37e"
    },
    "colab": {
      "name": "categorical_full.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Categorical Embedding"
      ],
      "metadata": {
        "id": "P2kqk3ht5ek2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries"
      ],
      "metadata": {
        "id": "0gyEZY_v5ek6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from itertools import chain\r\n",
        "from sklearn.preprocessing import OneHotEncoder\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from keras.metrics import top_k_categorical_accuracy\r\n",
        "from keras.models import Model\r\n",
        "from keras.layers import Dense, Dropout, Input, Embedding,Reshape, Concatenate, Conv1D, BatchNormalization, GlobalMaxPooling1D, MaxPooling1D\r\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, recall_score, precision_score, accuracy_score"
      ],
      "outputs": [],
      "metadata": {
        "id": "VTgc06pl5ek6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "device_name = tf.test.gpu_device_name()\r\n",
        "\r\n",
        "if device_name != '/device:GPU:0':\r\n",
        "\traise SystemError('GPU device not found')\r\n",
        "\r\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "outputs": [],
      "metadata": {
        "id": "T1e7gp_T5ek8",
        "outputId": "64a0690c-b30a-4187-ab4d-0f697463851d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "YxyURCCH5ek8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "data = pd.read_csv(\"./data/splited_full_RASFF_DATA.csv\", sep=\";\", header=0, index_col=0)\r\n",
        "data = data.sample(frac=1)\r\n",
        "\r\n",
        "data.head(1)"
      ],
      "outputs": [],
      "metadata": {
        "id": "kL7kuM_55ek9",
        "outputId": "d2b01c36-210e-4787-da00-258fb1f4b0e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "class Stage:\r\n",
        "\tdef __init__(self, input, output):\r\n",
        "\t\tself.input = input\r\n",
        "\t\tself.output = output\r\n",
        "\r\n",
        "\t\tself.x = data.iloc[:, input]\r\n",
        "\t\tself.y = data.iloc[:, output]\r\n",
        "\r\n",
        "\t\tself.x_train, self.y_train = None, None\r\n",
        "\t\tself.x_val, self.y_val = None, None\r\n",
        "\t\tself.x_test, self.y_test = None, None\r\n",
        "\r\n",
        "\t\tself.input_list_train, self.input_list_test, self.input_list_testval = None, None, None\r\n",
        "\r\n",
        "\t\tself.__transform()\r\n",
        "\r\n",
        "\tdef __transform(self):\r\n",
        "\t\tstrategy = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\r\n",
        "\t\tstrategy.fit(self.y.values)\r\n",
        "\r\n",
        "\t\tself.y = strategy.transform(self.y.values)\r\n",
        "\r\n",
        "\t\tself.x_train, self.x_test, self.y_train, self.y_test = train_test_split(self.x, self.y, test_size=0.2)\r\n",
        "\t\tself.x_train, self.x_val, self.y_train, self.y_val = train_test_split(self.x_train, self.y_train, test_size=0.25, random_state=42,shuffle = True)\r\n",
        "\r\n",
        "\tdef get_metrics(self):\r\n",
        "\t\tresult = model.predict(self.input_list_testval, batch_size=64)\r\n",
        "\t\tresult = np.argmax(result, axis=-1)\r\n",
        "\r\n",
        "\t\tprint(f\"- Accuracy: {round(accuracy_score(np.argmax(self.y_test, axis=-1), result)*100, 2)}%\")\r\n",
        "\t\tprint(f\"- Specifity: {round(get_specifity(np.argmax(self.y_test, axis=-1), result)*100, 2)}%\")\r\n",
        "\t\tprint(f\"- Sensitivity: {round(recall_score(np.argmax(self.y_test, axis=-1), result, average='macro', zero_division=0)*100, 2)}%\")\r\n",
        "\t\tprint(f\"- Precision: {round(precision_score(np.argmax(self.y_test, axis=-1), result, average='macro', zero_division=0)*100, 2)}%\")\r\n",
        "\r\n",
        "\t\tprint(classification_report(np.argmax(self.y_test, axis=-1), result, zero_division=True))\r\n",
        "\r\n",
        "\t\tcm = confusion_matrix(np.argmax(self.y_test, axis=-1), result)\r\n",
        "\t\tcm = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(range(0, cm.shape[0])))\r\n",
        "\r\n",
        "\t\t_, ax = plt.subplots(figsize=(10, 10))\r\n",
        "\t\tcm.plot(ax=ax)\r\n",
        "\r\n",
        "\t\tplt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "rCLp9pxV5ek9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "Ou0L8kNh5ek-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "data.DATE_CASE = data.DATE_CASE.astype(str)\r\n",
        "data.HAZARDS_CAT = data.HAZARDS_CAT.astype(str)\r\n",
        "data.COUNT_DESTIN = data.COUNT_DESTIN.astype(str)\r\n",
        "data.COUNT_CONCERN = data.COUNT_CONCERN.astype(str)\r\n",
        "\r\n",
        "data = data.dropna(subset=['DATE_CASE'])"
      ],
      "outputs": [],
      "metadata": {
        "id": "07xaGlha5ek_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def preproc(X_train, X_test, X_val):\r\n",
        "    input_list_train = []\r\n",
        "    input_list_test = []\r\n",
        "    input_list_testval = []\r\n",
        "    \r\n",
        "    for c in stage1.x.columns:\r\n",
        "        raw_vals = np.unique(X_train[c])\r\n",
        "        val_map = {}\r\n",
        "        for i in range(len(raw_vals)):\r\n",
        "            val_map[raw_vals[i]] = i       \r\n",
        "        \r\n",
        "        input_list_train.append(X_train[c].map(val_map).values)\r\n",
        "        input_list_test.append(X_test[c].map(val_map).fillna(0).values)\r\n",
        "        input_list_testval.append(X_val[c].map(val_map).fillna(0).values)\r\n",
        "\r\n",
        "    return input_list_train, input_list_test,input_list_testval"
      ],
      "outputs": [],
      "metadata": {
        "id": "Lmi0-QQu5ek_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def get_specifity(y_actual, y_pred):\r\n",
        "    TN = []\r\n",
        "    FP = []\r\n",
        "\r\n",
        "    for index ,_id in enumerate(np.union1d(y_actual, y_pred)):\r\n",
        "        FP.append(0)\r\n",
        "        TN.append(0)\r\n",
        "\r\n",
        "        for i in range(len(y_pred)):\r\n",
        "            if y_pred[i] == _id and y_actual[i] != y_pred[i]:\r\n",
        "                FP[index] += 1\r\n",
        "            if y_actual[i] == y_pred[i] != _id:\r\n",
        "                TN[index] += 1\r\n",
        "\r\n",
        "    TN = sum(TN)\r\n",
        "    FP = sum(FP)\r\n",
        "\r\n",
        "    return TN/(TN + FP)"
      ],
      "outputs": [],
      "metadata": {
        "id": "KTYtwzp_5elA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Mining"
      ],
      "metadata": {
        "id": "oPdLbXbZ5elG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "stage1 = Stage(\r\n",
        "\tinput=[0, 1, 6, 8],\r\n",
        "\toutput=[2]\r\n",
        ")\r\n",
        "\r\n",
        "# stage1 = Stage(\r\n",
        "# \tinput=[0, 1, 6, 8, 2],\r\n",
        "# \toutput=[7]\r\n",
        "# )\r\n",
        "\r\n",
        "# stage1 = Stage(\r\n",
        "# \tinput=[0, 1, 6, 8, 2, 7],\r\n",
        "# \toutput=[5]\r\n",
        "# )"
      ],
      "outputs": [],
      "metadata": {
        "id": "ERASg1JQ5elG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def top_1_categorical_accuracy(y_true, y_pred):\r\n",
        "\treturn top_k_categorical_accuracy(y_true, y_pred, k=1)\r\n",
        "\r\n",
        "def top_2_categorical_accuracy(y_true, y_pred):\r\n",
        "    return top_k_categorical_accuracy(y_true, y_pred, k=2)\r\n",
        "\r\n",
        "def top_3_categorical_accuracy(y_true, y_pred):\r\n",
        "    return top_k_categorical_accuracy(y_true, y_pred, k=3)"
      ],
      "outputs": [],
      "metadata": {
        "id": "PsrmLOS45elH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "input_models = []\r\n",
        "output_embeddings = []\r\n",
        "\r\n",
        "for categorical_var in stage1.x.columns:\r\n",
        "    cat_emb_name = categorical_var.replace(\" \", \"\") + \"_Embedding\"\r\n",
        "    input_name = \"Input_\" + categorical_var.replace(\" \", \"\")\r\n",
        "    no_of_unique_cat = stage1.x_train[categorical_var].nunique()\r\n",
        "    embedding_size = int(min(np.ceil((no_of_unique_cat)/2), 50))\r\n",
        "   \r\n",
        "    input_model = Input(shape=(1, ), name=input_name)\r\n",
        "    output_model = Embedding(no_of_unique_cat, embedding_size, name=cat_emb_name)(input_model)\r\n",
        "    output_model = Reshape(target_shape=(embedding_size, ))(output_model)    \r\n",
        "    \r\n",
        "    input_models.append(input_model)\r\n",
        "    output_embeddings.append(output_model)\r\n",
        "  \r\n",
        "output = Concatenate()(output_embeddings)\r\n",
        "output = Dense(2048,activation=\"relu\")(output)\r\n",
        "output = Dropout(0.3)(output)\r\n",
        "output = Dense(1024,activation=\"relu\")(output)\r\n",
        "output = Dropout(0.2)(output)\r\n",
        "output = Dense(512,activation=\"relu\")(output)\r\n",
        "output = Dropout(0.2)(output)\r\n",
        "output = Dense(stage1.y_val.shape[1], activation=\"softmax\")(output)\r\n",
        "\r\n",
        "model = Model(inputs=input_models, outputs=output)"
      ],
      "outputs": [],
      "metadata": {
        "id": "TeGqJXwb5elH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\", top_1_categorical_accuracy,top_2_categorical_accuracy,top_3_categorical_accuracy])\r\n",
        "\r\n",
        "model.summary()"
      ],
      "outputs": [],
      "metadata": {
        "id": "ZSnA3Bfg5elH",
        "outputId": "4aa54665-5a97-45eb-c137-0037391b2768",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "stage1.input_list_train, stage1.input_list_test, stage1.input_list_testval = preproc(stage1.x_train, stage1.x_test, stage1.x_val)\r\n",
        "\r\n",
        "hist = model.fit(stage1.input_list_train, stage1.y_train, validation_data=(stage1.input_list_testval, stage1.y_val), epochs=5, batch_size=64, verbose=1)"
      ],
      "outputs": [],
      "metadata": {
        "id": "O7TAH-wO5elI",
        "outputId": "876e41d7-e675-4743-9c3d-e34da5589682",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.style.use(\"ggplot\")\r\n",
        "\r\n",
        "plt.figure()\r\n",
        "\r\n",
        "plt.plot(hist.history[\"loss\"], label=\"train_loss\")\r\n",
        "plt.plot(hist.history[\"val_loss\"], label=\"val_loss\")\r\n",
        "plt.plot(hist.history[\"accuracy\"], label=\"train_acc\")\r\n",
        "plt.plot(hist.history[\"val_accuracy\"], label=\"val_acc\")\r\n",
        "\r\n",
        "plt.title(\"Training Loss and Accuracy\")\r\n",
        "plt.xlabel(\"Epoch #\")\r\n",
        "plt.ylabel(\"Loss/Accuracy\")\r\n",
        "plt.legend(loc=\"lower left\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "GQRwG6Mf5elI",
        "outputId": "c0ca2495-e904-46a2-b86f-a805e7f6ad68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "stage1.get_metrics()"
      ],
      "outputs": [],
      "metadata": {
        "id": "MISXn4is5elJ",
        "outputId": "184c4154-4a5a-4b24-8b97-43126b919d5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "historials = []\r\n",
        "evaluations = []\r\n",
        "\r\n",
        "for i in range (1, 6):\r\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\", top_1_categorical_accuracy, top_2_categorical_accuracy, top_3_categorical_accuracy])\r\n",
        "    \r\n",
        "    hist = model.fit(stage1.input_list_train, stage1.y_train, validation_data=(stage1.input_list_testval, stage1.y_val), epochs=25, batch_size=64, verbose=0)\r\n",
        "    historials.append(hist)\r\n",
        "    \r\n",
        "    evaluation = model.evaluate(x=stage1.input_list_testval, y=stage1.y_val)\r\n",
        "    evaluations.append(evaluation)\r\n",
        "    \r\n",
        "    model.save(\"model\" + str(i) + \".h5\")\r\n",
        "\r\n",
        "    stage1.get_metrics()\r\n",
        "\r\n",
        "    print(\"\\n\\n-----------------------\\n\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "cf2A3gcB5elJ",
        "outputId": "41509bc2-de86-45f7-a634-d61be4b22eff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "input_models = []\r\n",
        "output_embeddings = []\r\n",
        "\r\n",
        "for categorical_var in stage1.x.columns:\r\n",
        "\tcat_emb_name = categorical_var.replace(\" \", \"\") + \"_Embedding\"\r\n",
        "\tinput_name = \"Input_\" + categorical_var.replace(\" \", \"\")\r\n",
        "\tno_of_unique_cat  = stage1.x_train[categorical_var].nunique()\r\n",
        "\tembedding_size = int(min(np.ceil((no_of_unique_cat)/2), 50))\r\n",
        "\r\n",
        "\tinput_model = Input(shape=(1, ), name=input_name)\r\n",
        "\toutput_model = Embedding(no_of_unique_cat, embedding_size, name=cat_emb_name)(input_model)\r\n",
        "\toutput_model = Reshape(target_shape=(embedding_size, ))(output_model)    \r\n",
        "\r\n",
        "\tinput_models.append(input_model)\r\n",
        "\toutput_embeddings.append(output_model)\r\n",
        "  \r\n",
        "output = Concatenate()(output_embeddings)\r\n",
        "output = Reshape(input_shape=(100, ), target_shape=(sum([i.shape[1] for i in output_embeddings]), 1))(output)\r\n",
        "output = Conv1D(filters=128,kernel_size=4, activation = \"relu\")(output)\r\n",
        "output = Conv1D(filters=128,kernel_size=4, activation = \"relu\")(output)\r\n",
        "output = BatchNormalization()(output)\r\n",
        "output = MaxPooling1D(pool_size=2)(output)\r\n",
        "output = Conv1D(filters=256,kernel_size=3, activation = \"relu\")(output)\r\n",
        "output = Conv1D(filters=256,kernel_size=3, activation = \"relu\")(output)\r\n",
        "output = BatchNormalization()(output)\r\n",
        "output = GlobalMaxPooling1D()(output)\r\n",
        "output = Dense(512, activation = \"relu\")(output)\r\n",
        "output = Dense(256, activation = \"relu\")(output)\r\n",
        "output = Dense(stage1.y_val.shape[1], activation='softmax')(output)\r\n",
        "\r\n",
        "model = Model(inputs=input_models, outputs=output)"
      ],
      "outputs": [],
      "metadata": {
        "id": "1x0uVBEq5elJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=[top_1_categorical_accuracy,top_2_categorical_accuracy,top_3_categorical_accuracy])\r\n",
        "\r\n",
        "model.summary()"
      ],
      "outputs": [],
      "metadata": {
        "id": "qqfN5aHB5elK",
        "outputId": "4c75518e-608d-4eb5-f7ec-ec4f7f709a21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "stage1.input_list_train, stage1.input_list_test, stage1.input_list_testval = preproc(stage1.x_train, stage1.x_test, stage1.x_val)\r\n",
        "\r\n",
        "hist = model.fit(stage1.input_list_train, stage1.y_train, validation_data=(stage1.input_list_testval, stage1.y_val) , epochs =  25, batch_size = 64, verbose= 1)"
      ],
      "outputs": [],
      "metadata": {
        "id": "qF5WT08p5elK",
        "outputId": "175c6009-df15-4148-b86b-3a428639c9ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model.evaluate(x=stage1.input_list_testval, y=stage1.y_val)\r\n",
        "\r\n",
        "stage1.get_metrics()"
      ],
      "outputs": [],
      "metadata": {
        "id": "RfHwCtzD5elK",
        "outputId": "779bc3f6-c45b-4158-f551-ad672c4ef5af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      }
    }
  ]
}