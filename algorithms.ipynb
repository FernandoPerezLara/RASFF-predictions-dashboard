{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Non-neural models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "from google.colab import files\r\n",
    "from sklearn import tree\r\n",
    "from sklearn.feature_extraction import FeatureHasher\r\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV \r\n",
    "from sklearn.ensemble import GradientBoostingClassifier,AdaBoostClassifier, RandomForestClassifier\r\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, MultiLabelBinarizer\r\n",
    "from sklearn.metrics import classification_report, accuracy_score, recall_score, precision_score, confusion_matrix, ConfusionMatrixDisplay\r\n",
    "from itertools import chain\r\n",
    "from sklearn.linear_model import LogisticRegression"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Code"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "data = pd.read_csv(\"./data/splited_full_RASFF_DATA.csv\", sep=\";\", header=0, index_col=0)\r\n",
    "\r\n",
    "data.head(3)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE_CASE</th>\n",
       "      <th>NOT_COUNTRY</th>\n",
       "      <th>PROD_CAT</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>RISK_DECISION</th>\n",
       "      <th>ACTION_TAKEN</th>\n",
       "      <th>DISTRIBUTION_STAT</th>\n",
       "      <th>HAZARDS_CAT</th>\n",
       "      <th>COUNT_ORIGEN</th>\n",
       "      <th>COUNT_DESTIN</th>\n",
       "      <th>COUNT_CONCERN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-10-16</td>\n",
       "      <td>France</td>\n",
       "      <td>meat and meat products (other than poultry)</td>\n",
       "      <td>food</td>\n",
       "      <td>serious</td>\n",
       "      <td>recall from consumers</td>\n",
       "      <td>distribution to other member countries</td>\n",
       "      <td>microbial contaminants (other)</td>\n",
       "      <td>France</td>\n",
       "      <td>Czech Republic</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-16</td>\n",
       "      <td>France</td>\n",
       "      <td>meat and meat products (other than poultry)</td>\n",
       "      <td>food</td>\n",
       "      <td>serious</td>\n",
       "      <td>recall from consumers</td>\n",
       "      <td>distribution to other member countries</td>\n",
       "      <td>microbial contaminants (other)</td>\n",
       "      <td>France</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-10-16</td>\n",
       "      <td>Bulgaria</td>\n",
       "      <td>fruits and vegetables</td>\n",
       "      <td>food</td>\n",
       "      <td>serious</td>\n",
       "      <td>destruction</td>\n",
       "      <td>product not (yet) placed on the market</td>\n",
       "      <td>pesticide residues</td>\n",
       "      <td>Turkey</td>\n",
       "      <td></td>\n",
       "      <td>Bulgaria</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DATE_CASE NOT_COUNTRY                                     PROD_CAT  TYPE  \\\n",
       "0  2020-10-16      France  meat and meat products (other than poultry)  food   \n",
       "1  2020-10-16      France  meat and meat products (other than poultry)  food   \n",
       "2  2020-10-16    Bulgaria                        fruits and vegetables  food   \n",
       "\n",
       "  RISK_DECISION           ACTION_TAKEN  \\\n",
       "0       serious  recall from consumers   \n",
       "1       serious  recall from consumers   \n",
       "2       serious            destruction   \n",
       "\n",
       "                        DISTRIBUTION_STAT                     HAZARDS_CAT  \\\n",
       "0  distribution to other member countries  microbial contaminants (other)   \n",
       "1  distribution to other member countries  microbial contaminants (other)   \n",
       "2  product not (yet) placed on the market              pesticide residues   \n",
       "\n",
       "  COUNT_ORIGEN    COUNT_DESTIN COUNT_CONCERN  \n",
       "0       France  Czech Republic                \n",
       "1       France  United Kingdom                \n",
       "2       Turkey                      Bulgaria  "
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "class Stage:\r\n",
    "\tdef __init__(self, input, output):\r\n",
    "\t\tself.input = input\r\n",
    "\t\tself.output = output\r\n",
    "\r\n",
    "\t\tself.cm_name = \"\"\r\n",
    "\r\n",
    "\t\tself.x = data.iloc[:, input]\r\n",
    "\t\tself.y = data.iloc[:, output]\r\n",
    "\r\n",
    "\t\tself.x_train, self.x_test, self.y_train, self.y_test = None, None, None, None\r\n",
    "\r\n",
    "\t\tself.classifier = self.Classifier()\r\n",
    "\t\t\r\n",
    "\t\tself.__transform()\r\n",
    "\r\n",
    "\tdef __transform(self):\r\n",
    "\t\tselection = 1\r\n",
    "\r\n",
    "\t\tif selection == 1:\r\n",
    "\t\t\tstrategy = OneHotEncoder(handle_unknown=\"ignore\") # One Hot Encoder\r\n",
    "\t\t\tself.cm_name = \"ohe\"\r\n",
    "\t\telif selection == 2:\r\n",
    "\t\t\tstrategy = OrdinalEncoder() # Integer\r\n",
    "\t\t\tself.cm_name = \"int\"\r\n",
    "\t\telif selection == 3:\r\n",
    "\t\t\tstrategy = FeatureHasher(n_features=25, input_type=\"string\") # Hashing\r\n",
    "\t\t\tself.cm_name = \"hsh\"\r\n",
    "\t\telif selection == 4:\r\n",
    "\t\t\tstrategy = MultiLabelBinarizer() # Binary\r\n",
    "\t\t\tself.cm_name = \"bnr\"\r\n",
    "\t\telse:\r\n",
    "\t\t\tprint(\"Invalid selection\")\r\n",
    "\t\t\r\n",
    "\t\tstrategy.fit(self.x.values)\r\n",
    "\t\t\r\n",
    "\t\tself.x_train, self.x_test, self.y_train, self.y_test = train_test_split(strategy.transform(self.x.values), self.y, test_size=0.2)\r\n",
    "\r\n",
    "\tclass Classifier:\r\n",
    "\t\tpass"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def get_specifity(y_actual, y_pred):\r\n",
    "    TN = []\r\n",
    "    FP = []\r\n",
    "\r\n",
    "    for index ,_id in enumerate(np.union1d(y_actual, y_pred)):\r\n",
    "        FP.append(0)\r\n",
    "        TN.append(0)\r\n",
    "\r\n",
    "        for i in range(len(y_pred)):\r\n",
    "            if y_pred[i] == _id and y_actual[i] != y_pred[i]:\r\n",
    "                FP[index] += 1\r\n",
    "            if y_actual[i] == y_pred[i] != _id:\r\n",
    "                TN[index] += 1\r\n",
    "\r\n",
    "    TN = sum(TN)\r\n",
    "    FP = sum(FP)\r\n",
    "\r\n",
    "    return TN/(TN + FP)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "data.DATE_CASE = data.DATE_CASE.astype(str)\r\n",
    "data.HAZARDS_CAT = data.HAZARDS_CAT.astype(str)\r\n",
    "data.COUNT_DESTIN = data.COUNT_DESTIN.astype(str)\r\n",
    "data.COUNT_CONCERN = data.COUNT_CONCERN.astype(str)\r\n",
    "data = data.dropna(subset=['DATE_CASE'])\r\n",
    "\r\n",
    "# data.dropna(subset=data.columns[[1, 3, 5, 8, 9, 12, 13]], inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "data = data.sample(frac=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transformation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# def chainer(s):\r\n",
    "#     return list(chain.from_iterable(s.str.split(',')))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# lens = data['HAZARDS_CAT'].str.split(',').map(len)\r\n",
    "# split1 = pd.DataFrame({'DATE_CASE': np.repeat(data['DATE_CASE'], lens),\r\n",
    "#                     'NOT_COUNTRY': np.repeat(data['NOT_COUNTRY'], lens),\r\n",
    "#                     'PROD_CAT': np.repeat(data['PROD_CAT'], lens),\r\n",
    "#                     'TYPE': np.repeat(data['TYPE'], lens),\r\n",
    "#                     'RISK_DECISION': np.repeat(data['RISK_DECISION'], lens),\r\n",
    "#                     'ACTION_TAKEN': np.repeat(data['ACTION_TAKEN'], lens),\r\n",
    "#                     'DISTRIBUTION_STAT': np.repeat(data['DISTRIBUTION_STAT'], lens),\r\n",
    "#                     'HAZARDS_CAT': chainer(data['HAZARDS_CAT']),\r\n",
    "#                     'COUNT_ORIGEN': np.repeat(data['COUNT_ORIGEN'], lens),\r\n",
    "#                     'COUNT_DESTIN': np.repeat(data['COUNT_DESTIN'], lens),\r\n",
    "#                     'COUNT_CONCERN': np.repeat(data['COUNT_CONCERN'], lens)})\r\n",
    "\r\n",
    "# lens = split1['COUNT_ORIGEN'].str.split(',').map(len)\r\n",
    "# split2 = pd.DataFrame({'DATE_CASE': np.repeat(split1['DATE_CASE'], lens),\r\n",
    "#                     'NOT_COUNTRY': np.repeat(split1['NOT_COUNTRY'], lens),\r\n",
    "#                     'PROD_CAT': np.repeat(split1['PROD_CAT'], lens),\r\n",
    "#                     'TYPE': np.repeat(split1['TYPE'], lens),\r\n",
    "#                     'RISK_DECISION': np.repeat(split1['RISK_DECISION'], lens),\r\n",
    "#                     'ACTION_TAKEN': np.repeat(split1['ACTION_TAKEN'], lens),\r\n",
    "#                     'DISTRIBUTION_STAT': np.repeat(split1['DISTRIBUTION_STAT'], lens),\r\n",
    "#                     'HAZARDS_CAT': np.repeat(split1['HAZARDS_CAT'], lens),\r\n",
    "#                     'COUNT_ORIGEN': chainer(split1['COUNT_ORIGEN']),\r\n",
    "#                     'COUNT_DESTIN': np.repeat(split1['COUNT_DESTIN'], lens),\r\n",
    "#                     'COUNT_CONCERN': np.repeat(split1['COUNT_CONCERN'], lens)})\r\n",
    "\r\n",
    "# lens = split2['COUNT_DESTIN'].str.split(',').map(len)\r\n",
    "# split3 = pd.DataFrame({'DATE_CASE': np.repeat(split2['DATE_CASE'], lens),\r\n",
    "#                     'NOT_COUNTRY': np.repeat(split2['NOT_COUNTRY'], lens),\r\n",
    "#                     'PROD_CAT': np.repeat(split2['PROD_CAT'], lens),\r\n",
    "#                     'TYPE': np.repeat(split2['TYPE'], lens),\r\n",
    "#                     'RISK_DECISION': np.repeat(split2['RISK_DECISION'], lens),\r\n",
    "#                     'ACTION_TAKEN': np.repeat(split2['ACTION_TAKEN'], lens),\r\n",
    "#                     'DISTRIBUTION_STAT': np.repeat(split2['DISTRIBUTION_STAT'], lens),\r\n",
    "#                     'HAZARDS_CAT': np.repeat(split2['HAZARDS_CAT'], lens),\r\n",
    "#                     'COUNT_ORIGEN': np.repeat(split2['COUNT_ORIGEN'], lens),\r\n",
    "#                     'COUNT_DESTIN': chainer(split2['COUNT_DESTIN']),\r\n",
    "#                     'COUNT_CONCERN': np.repeat(split2['COUNT_CONCERN'], lens)})\r\n",
    "\r\n",
    "# lens = split3['COUNT_CONCERN'].str.split(',').map(len)\r\n",
    "# split4 = pd.DataFrame({'DATE_CASE': np.repeat(split3['DATE_CASE'], lens),\r\n",
    "#                     'NOT_COUNTRY': np.repeat(split3['NOT_COUNTRY'], lens),\r\n",
    "#                     'PROD_CAT': np.repeat(split3['PROD_CAT'], lens),\r\n",
    "#                     'TYPE': np.repeat(split3['TYPE'], lens),\r\n",
    "#                     'RISK_DECISION': np.repeat(split3['RISK_DECISION'], lens),\r\n",
    "#                     'ACTION_TAKEN': np.repeat(split3['ACTION_TAKEN'], lens),\r\n",
    "#                     'DISTRIBUTION_STAT': np.repeat(split3['DISTRIBUTION_STAT'], lens),\r\n",
    "#                     'HAZARDS_CAT': np.repeat(split3['HAZARDS_CAT'], lens),\r\n",
    "#                     'COUNT_ORIGEN': np.repeat(split3['COUNT_ORIGEN'], lens),\r\n",
    "#                     'COUNT_DESTIN': np.repeat(split3['COUNT_DESTIN'], lens),\r\n",
    "#                     'COUNT_CONCERN': chainer(split3['COUNT_CONCERN'])})\r\n",
    "\r\n",
    "# split4 = split4.reset_index(drop = True)\r\n",
    "# split4 = split4.dropna(subset = ['DATE_CASE'])\r\n",
    "\r\n",
    "# data = split4.copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "data.head(3)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE_CASE</th>\n",
       "      <th>NOT_COUNTRY</th>\n",
       "      <th>PROD_CAT</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>RISK_DECISION</th>\n",
       "      <th>ACTION_TAKEN</th>\n",
       "      <th>DISTRIBUTION_STAT</th>\n",
       "      <th>HAZARDS_CAT</th>\n",
       "      <th>COUNT_ORIGEN</th>\n",
       "      <th>COUNT_DESTIN</th>\n",
       "      <th>COUNT_CONCERN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19231</th>\n",
       "      <td>2019-06-19</td>\n",
       "      <td>Poland</td>\n",
       "      <td>poultry meat and poultry meat products</td>\n",
       "      <td>food</td>\n",
       "      <td>serious</td>\n",
       "      <td>detained by operator</td>\n",
       "      <td>product (presumably) no longer on the market</td>\n",
       "      <td>pathogenic micro-organisms</td>\n",
       "      <td>Poland</td>\n",
       "      <td>Poland</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60451</th>\n",
       "      <td>2016-07-22</td>\n",
       "      <td>Italy</td>\n",
       "      <td>fish and fish products</td>\n",
       "      <td>food</td>\n",
       "      <td>serious</td>\n",
       "      <td>official detention</td>\n",
       "      <td>product (presumably) no longer on the market</td>\n",
       "      <td>metals</td>\n",
       "      <td>Spain</td>\n",
       "      <td></td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16130</th>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>Malta</td>\n",
       "      <td>herbs and spices</td>\n",
       "      <td>food</td>\n",
       "      <td>not serious</td>\n",
       "      <td>destruction</td>\n",
       "      <td>product not (yet) placed on the market</td>\n",
       "      <td>food additives and flavourings</td>\n",
       "      <td>South Africa</td>\n",
       "      <td></td>\n",
       "      <td>Malta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATE_CASE NOT_COUNTRY                                PROD_CAT  TYPE  \\\n",
       "19231  2019-06-19      Poland  poultry meat and poultry meat products  food   \n",
       "60451  2016-07-22       Italy                  fish and fish products  food   \n",
       "16130  2019-08-30       Malta                        herbs and spices  food   \n",
       "\n",
       "      RISK_DECISION          ACTION_TAKEN  \\\n",
       "19231       serious  detained by operator   \n",
       "60451       serious    official detention   \n",
       "16130   not serious           destruction   \n",
       "\n",
       "                                  DISTRIBUTION_STAT  \\\n",
       "19231  product (presumably) no longer on the market   \n",
       "60451  product (presumably) no longer on the market   \n",
       "16130        product not (yet) placed on the market   \n",
       "\n",
       "                          HAZARDS_CAT  COUNT_ORIGEN COUNT_DESTIN COUNT_CONCERN  \n",
       "19231      pathogenic micro-organisms        Poland       Poland                \n",
       "60451                          metals         Spain                      Italy  \n",
       "16130  food additives and flavourings  South Africa                      Malta  "
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "stage1 = Stage(\r\n",
    "\t# input=[0, 1, 6, 8],\r\n",
    "\t# input=[1, 3, 9, 13],\r\n",
    "\t# output=[5] # Product category\r\n",
    "\t\r\n",
    "\tinput=[0, 1, 6, 8],\r\n",
    "\toutput=[2]\r\n",
    ")\r\n",
    "\r\n",
    "stage2 = Stage(\r\n",
    "\t# input=[0, 1, 2, 6, 8],\r\n",
    "\t# input=[1, 3, 9, 13, 5],\r\n",
    "\t# output=[12] # Hazard category\r\n",
    "\t\r\n",
    "\tinput=[0, 1, 6, 8, 2],\r\n",
    "\toutput=[7]\r\n",
    ")\r\n",
    "\r\n",
    "stage3 = Stage(\r\n",
    "\t# input=[0, 1, 2, 6, 7, 8],\r\n",
    "\t# input=[1, 3, 9, 13, 5, 12],\r\n",
    "\t# output=[8] # Decision taken\r\n",
    "\t\r\n",
    "\tinput=[0, 1, 6, 8, 2, 7],\r\n",
    "\toutput=[5]\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data mining"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decision trees"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class DecisionTree:\r\n",
    "\tdef __init__(self, stage, params, number):\r\n",
    "\t\tself.stage = stage\r\n",
    "\t\tself.params = params\r\n",
    "\t\tself.number = number\r\n",
    "\r\n",
    "\t\tself.classifier = GridSearchCV(tree.DecisionTreeClassifier(random_state=42), self.params, cv=3, verbose=3)\r\n",
    "\t\tself.classifier.fit(stage.x_train, stage.y_train)\r\n",
    "\r\n",
    "\t\tself.best_params = self.classifier.best_params_\r\n",
    "\r\n",
    "\t\tself.classifier = tree.DecisionTreeClassifier(**self.best_params, random_state=42)\r\n",
    "\t\tself.classifier.fit(stage.x_train, stage.y_train)\r\n",
    "\r\n",
    "\t\tself.y_predict = None\r\n",
    "\r\n",
    "\tdef predict(self):\r\n",
    "\t\tself.y_predict = self.classifier.predict(self.stage.x_test)\r\n",
    "\r\n",
    "\tdef get_metrics(self):\r\n",
    "\t\tprint(f\"- Accuracy: {round(accuracy_score(self.stage.y_test, self.y_predict)*100, 2)}%\")\r\n",
    "\t\tprint(f\"- Specifity: {round(get_specifity(self.stage.y_test.values, self.y_predict)*100, 2)}%\")\r\n",
    "\t\tprint(f\"- Sensitivity: {round(recall_score(self.stage.y_test, self.y_predict, average='macro', zero_division=0)*100, 2)}%\")\r\n",
    "\t\tprint(f\"- Precision: {round(precision_score(self.stage.y_test, self.y_predict, average='macro', zero_division=0)*100, 2)}%\")\r\n",
    "\t\t\r\n",
    "\t\tprint(classification_report(self.stage.y_test, self.y_predict, zero_division=0))\r\n",
    "\r\n",
    "\t\tcm = confusion_matrix(self.stage.y_test, self.y_predict)\r\n",
    "\t\tcm = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(range(0, cm.shape[0])))\r\n",
    "\r\n",
    "\t\tfig, ax = plt.subplots(figsize=(10, 10))\r\n",
    "\t\tcm.plot(ax=ax)\r\n",
    "\r\n",
    "\t\tself.stage.classifier.decision_tree.fig.savefig(\"dt_\" + self.stage.cm_name + \"_\" + self.number + \".png\")\r\n",
    "\t\tfiles.download(\"dt_\" + self.stage.cm_name + \"_2\" + \".png\")\r\n",
    "\r\n",
    "\t\tplt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "params = {\r\n",
    "\t\"criterion\": [\"gini\", \"entropy\"],\r\n",
    "\t\"splitter\": [\"best\", \"random\"],\r\n",
    "\t\"max_features\": [\"auto\", \"sqrt\", \"log2\"]\r\n",
    "}\r\n",
    "\r\n",
    "stage1.classifier.decision_tree = DecisionTree(stage1, params, 1)\r\n",
    "print(f\"Stage 1 completed: {stage1.classifier.decision_tree.best_params}\")\r\n",
    "\r\n",
    "stage2.classifier.decision_tree = DecisionTree(stage2, params, 2)\r\n",
    "print(f\"Stage 2 completed: {stage2.classifier.decision_tree.best_params}\")\r\n",
    "\r\n",
    "stage3.classifier.decision_tree = DecisionTree(stage3, params, 3)\r\n",
    "print(f\"Stage 3 completed: {stage3.classifier.decision_tree.best_params}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "stage1.classifier.decision_tree.predict()\r\n",
    "stage2.classifier.decision_tree.predict()\r\n",
    "stage3.classifier.decision_tree.predict()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Stage 1\")\r\n",
    "stage1.classifier.decision_tree.get_metrics()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Stage 2\")\r\n",
    "stage2.classifier.decision_tree.get_metrics()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Stage 3\")\r\n",
    "stage3.classifier.decision_tree.get_metrics()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Boosted trees"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class BoostedTrees:\r\n",
    "\tdef __init__(self, stage, params):\r\n",
    "\t\tself.stage = stage\r\n",
    "\t\tself.params = params\r\n",
    "\t\t\r\n",
    "\t\tself.classifier = GridSearchCV(GradientBoostingClassifier(max_features=\"sqrt\", subsample=0.8, random_state=10), self.params, n_jobs=4, cv=3, verbose=3)\r\n",
    "\t\tself.classifier.fit(stage.x_train, stage.y_train.values.ravel())\r\n",
    "\r\n",
    "\t\tself.best_params = self.classifier.best_params_\r\n",
    "\r\n",
    "\t\tself.classifier = GradientBoostingClassifier(**self.best_params, max_features=\"sqrt\", subsample=0.8, random_state=10)\r\n",
    "\t\tself.classifier.fit(stage.x_train, stage.y_train.values.ravel())\r\n",
    "\r\n",
    "\t\tself.y_predict = None\r\n",
    "\r\n",
    "\tdef predict(self):\r\n",
    "\t\tself.y_predict = self.classifier.predict(self.stage.x_test)\r\n",
    "\r\n",
    "\tdef get_metrics(self):\r\n",
    "\t\tprint(f\"- Accuracy: {round(accuracy_score(self.stage.y_test, self.y_predict)*100, 2)}%\")\r\n",
    "\t\tprint(f\"- Specifity: {round(get_specifity(self.stage.y_test.values, self.y_predict)*100, 2)}%\")\r\n",
    "\t\tprint(f\"- Sensitivity: {round(recall_score(self.stage.y_test, self.y_predict, average='macro', zero_division=0)*100, 2)}%\")\r\n",
    "\t\tprint(f\"- Precission: {round(precision_score(self.stage.y_test, self.y_predict, average='macro', zero_division=0)*100, 2)}%\")\r\n",
    "\t\t\r\n",
    "\t\tprint(classification_report(self.stage.y_test, self.y_predict, zero_division=0))\r\n",
    "\r\n",
    "\t\tcm = confusion_matrix(self.stage.y_test, self.y_predict)\r\n",
    "\t\tcm = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(range(0, cm.shape[0])))\r\n",
    "\r\n",
    "\t\t_, ax = plt.subplots(figsize=(10, 10))\r\n",
    "\t\tcm.plot(ax=ax)\r\n",
    "\t\tplt.savefig('matrixConfusion.png')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "params = {\r\n",
    "\t\"n_estimators\": range(20, 51, 10),\r\n",
    "\t\"learning_rate\": [1, 0.1, 0.01],\r\n",
    "\t\"max_depth\": range(5, 10, 2),\r\n",
    "\t\"min_samples_split\": range(200, 601, 200)\r\n",
    "}\r\n",
    "\r\n",
    "stage1.classifier.boosted_trees = BoostedTrees(stage1, params)\r\n",
    "print(f\"Stage 1 completed: {stage1.classifier.boosted_trees.best_params}\")\r\n",
    "\r\n",
    "stage2.classifier.boosted_trees = BoostedTrees(stage2, params)\r\n",
    "print(f\"Stage 2 completed: {stage2.classifier.boosted_trees.best_params}\")\r\n",
    "\r\n",
    "stage3.classifier.boosted_trees = BoostedTrees(stage3, params)\r\n",
    "print(f\"Stage 3 completed: {stage3.classifier.boosted_trees.best_params}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "stage1.classifier.boosted_trees.predict()\r\n",
    "stage2.classifier.boosted_trees.predict()\r\n",
    "stage3.classifier.boosted_trees.predict()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Stage 1\")\r\n",
    "stage1.classifier.boosted_trees.get_metrics()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Stage 2\")\r\n",
    "stage2.classifier.boosted_trees.get_metrics()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Stage 3\")\r\n",
    "stage3.classifier.boosted_trees.get_metrics()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random Forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "class RandomForest:\r\n",
    "\tdef __init__(self, stage,params):\r\n",
    "\t\tself.stage = stage\r\n",
    "\t\tself.params=params\r\n",
    "\t\t\r\n",
    "\r\n",
    "\t\trf = RandomForestClassifier()\r\n",
    "\r\n",
    "\r\n",
    "\t\tself.classifier = GridSearchCV(estimator = rf, param_grid = self.params, \r\n",
    "                          cv = 3, n_jobs = -1, verbose = 2, verbose=3)\r\n",
    "\t\tself.classifier.fit(stage.x_train, stage.y_train)\r\n",
    "\r\n",
    "\t\tself.best_params = self.classifier.best_params_\r\n",
    "\r\n",
    "\t\tself.classifier = RandomForestClassifier(**self.best_params)\r\n",
    "\t\tself.classifier.fit(stage.x_train, stage.y_train)\r\n",
    "\r\n",
    "\t\tself.y_predict = None\r\n",
    "\r\n",
    "\tdef predict(self):\r\n",
    "\t\tself.y_predict = self.classifier.predict(self.stage.x_test)\r\n",
    "\r\n",
    "\tdef get_metrics(self):\r\n",
    "\t\tprint(f\"- Accuracy: {round(accuracy_score(self.stage.y_test, self.y_predict)*100, 2)}%\")\r\n",
    "\t\tprint(f\"- Specifity: {round(get_specifity(self.stage.y_test.values, self.y_predict)*100, 2)}%\")\r\n",
    "\t\tprint(f\"- Sensitivity: {round(recall_score(self.stage.y_test, self.y_predict, average='macro', zero_division=0)*100, 2)}%\")\r\n",
    "\t\tprint(f\"- Precision: {round(precision_score(self.stage.y_test, self.y_predict, average='macro', zero_division=0)*100, 2)}%\")\r\n",
    "\t\t\r\n",
    "\t\tprint(classification_report(self.stage.y_test, self.y_predict, zero_division=0))\r\n",
    "\r\n",
    "\t\tcm = confusion_matrix(self.stage.y_test, self.y_predict)\r\n",
    "\t\tcm = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(range(0, cm.shape[0])))\r\n",
    "\r\n",
    "\t\t_, ax = plt.subplots(figsize=(10, 10))\r\n",
    "\t\tcm.plot(ax=ax)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "params = {\r\n",
    "    'bootstrap': [True],\r\n",
    "    'max_depth': [100, 110],\r\n",
    "    'max_features': [2, 3],\r\n",
    "    'min_samples_leaf': [4, 5],\r\n",
    "    'min_samples_split': [10, 12],\r\n",
    "    'n_estimators': [200, 300, 500]}\r\n",
    "\r\n",
    "stage1.classifier.Random_forest = RandomForest(stage1, params)\r\n",
    "print(f\"Stage 1 completed: {stage1.classifier.Random_forest.best_params}\")\r\n",
    "\r\n",
    "stage2.classifier.Random_forest = RandomForest(stage2, params)\r\n",
    "print(f\"Stage 2 completed: {stage2.classifier.Random_forest.best_params}\")\r\n",
    "\r\n",
    "stage3.classifier.Random_forest = RandomForest(stage3, params)\r\n",
    "print(f\"Stage 3 completed: {stage3.classifier.Random_forest.best_params}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "stage1.classifier.Random_forest.predict()\r\n",
    "stage2.classifier.Random_forest.predict()\r\n",
    "stage3.classifier.Random_forest.predict()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Stage 1\")\r\n",
    "stage1.classifier.Random_forest.get_metrics()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Stage 2\")\r\n",
    "stage2.classifier.Random_forest.get_metrics()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Stage 3\")\r\n",
    "stage3.classifier.Random_forest.get_metrics()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logistic Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class LogisticRegression1:\r\n",
    "\tdef __init__(self, stage, params):\r\n",
    "\t\tself.stage = stage\r\n",
    "\t\tself.params = params\r\n",
    "\r\n",
    "\t\tself.classifier = GridSearchCV(LogisticRegression(), param_grid=self.params, scoring=\"recall\", verbose=3)\r\n",
    "\t\tself.classifier.fit(stage.x_train, stage.y_train)\r\n",
    "\r\n",
    "\t\tself.best_params = self.classifier.best_params_\r\n",
    "\r\n",
    "\t\tself.classifier = LogisticRegression(**self.best_params)\r\n",
    "\t\tself.classifier.fit(stage.x_train, stage.y_train)\r\n",
    "\r\n",
    "\t\tself.y_predict = None\r\n",
    "\r\n",
    "\tdef predict(self):\r\n",
    "\t\tself.y_predict = self.classifier.predict(self.stage.x_test)\r\n",
    "\r\n",
    "\tdef get_metrics(self):\r\n",
    "\t\tprint(f\"- Accuracy: {round(accuracy_score(self.stage.y_test, self.y_predict)*100, 2)}%\")\r\n",
    "\t\tprint(f\"- Specifity: {round(get_specifity(self.stage.y_test.values, self.y_predict)*100, 2)}%\")\r\n",
    "\t\tprint(f\"- Sensitivity: {round(recall_score(self.stage.y_test, self.y_predict, average='macro', zero_division=0)*100, 2)}%\")\r\n",
    "\t\tprint(f\"- Precision: {round(precision_score(self.stage.y_test, self.y_predict, average='macro', zero_division=0)*100, 2)}%\")\r\n",
    "\t\t\r\n",
    "\t\tprint(classification_report(self.stage.y_test, self.y_predict, zero_division=0))\r\n",
    "\r\n",
    "\t\tcm = confusion_matrix(self.stage.y_test, self.y_predict)\r\n",
    "\t\tcm = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(range(0, cm.shape[0])))\r\n",
    "\r\n",
    "\t\t_, ax = plt.subplots(figsize=(10, 10))\r\n",
    "\t\tcm.plot(ax=ax)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "params = {\r\n",
    "\t\"penalty\": [\"l2\"],\r\n",
    "\t\"C\": [0.001, 0.01, 0.1, 1, 10]\r\n",
    "}\r\n",
    "\r\n",
    "stage1.classifier.Logistic_regression = LogisticRegression1(stage1, params)\r\n",
    "print(f\"Stage 1 completed: {stage1.classifier.Logistic_regression.best_params}\")\r\n",
    "\r\n",
    "stage2.classifier.Logistic_regression = LogisticRegression1(stage2, params)\r\n",
    "print(f\"Stage 2 completed: {stage2.classifier.Logistic_regression.best_params}\")\r\n",
    "\r\n",
    "stage3.classifier.Logistic_regression = LogisticRegression1(stage3, params)\r\n",
    "print(f\"Stage 3 completed: {stage3.classifier.Logistic_regression.best_params}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "stage1.classifier.Random_forest.predict()\r\n",
    "stage2.classifier.Random_forest.predict()\r\n",
    "stage3.classifier.Random_forest.predict()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Stage 1\")\r\n",
    "stage1.classifier.Random_forest.get_metrics()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Stage 2\")\r\n",
    "stage2.classifier.Random_forest.get_metrics()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Stage 3\")\r\n",
    "stage3.classifier.Random_forest.get_metrics()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Support vector machine"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class SupportVectorMachine:\r\n",
    "\tdef __init__(self, stage, params):\r\n",
    "\t\tself.stage = stage\r\n",
    "\t\tself.params = params\r\n",
    "\t\t\r\n",
    "\t\tself.classifier = GridSearchCV(svm.SVC(), self.params, refit=True, verbose=3)\r\n",
    "\t\tself.classifier.fit(stage.x_train, stage.y_train.values.ravel())\r\n",
    "\r\n",
    "\t\tself.best_params = self.classifier.best_params_\r\n",
    "\r\n",
    "\t\tself.classifier = svm.SVC(**self.best_params)\r\n",
    "\t\tself.classifier.fit(stage.x_train, stage.y_train.values.ravel())\r\n",
    "\r\n",
    "\t\tself.y_predict = None\r\n",
    "\r\n",
    "\tdef predict(self):\r\n",
    "\t\tself.y_predict = self.classifier.predict(self.stage.x_test)\r\n",
    "\r\n",
    "\tdef get_metrics(self):\r\n",
    "\t\tprint(f\"- Accuracy: {round(accuracy_score(self.stage.y_test, self.y_predict)*100, 2)}%\")\r\n",
    "\t\tprint(f\"- Specifity: {round(get_specifity(self.stage.y_test.values, self.y_predict)*100, 2)}%\")\r\n",
    "\t\tprint(f\"- Sensitivity: {round(recall_score(self.stage.y_test, self.y_predict, average='macro', zero_division=0)*100, 2)}%\")\r\n",
    "\t\tprint(f\"- Precission: {round(precision_score(self.stage.y_test, self.y_predict, average='macro', zero_division=0)*100, 2)}%\")\r\n",
    "\t\t\r\n",
    "\t\tprint(classification_report(self.stage.y_test, self.y_predict, zero_division=0))\r\n",
    "\r\n",
    "\t\tcm = confusion_matrix(self.stage.y_test, self.y_predict)\r\n",
    "\t\tcm = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(range(0, cm.shape[0])))\r\n",
    "\r\n",
    "\t\t_, ax = plt.subplots(figsize=(10, 10))\r\n",
    "\t\tcm.plot(ax=ax)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "params = {\r\n",
    "\t\"C\": [0.1, 1, 10], \r\n",
    "    \"gamma\": [1, 0.1, 0.01],\r\n",
    "    \"kernel\": [\"rbf\"]\r\n",
    "} \r\n",
    "\r\n",
    "stage1.classifier.support_vector_machine = SupportVectorMachine(stage1, params)\r\n",
    "print(f\"Stage 1 completed: {stage1.classifier.support_vector_machine.best_params}\")\r\n",
    "\r\n",
    "stage2.classifier.support_vector_machine = SupportVectorMachine(stage2, params)\r\n",
    "print(f\"Stage 2 completed: {stage2.classifier.support_vector_machine.best_params}\")\r\n",
    "\r\n",
    "stage3.classifier.support_vector_machine = SupportVectorMachine(stage3, params)\r\n",
    "print(f\"Stage 3 completed: {stage3.classifier.support_vector_machine.best_params}\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('ceiec': conda)"
  },
  "interpreter": {
   "hash": "d98ed641ffb0afae769cd9f96943c7d5fe6ff4d949b5ee86e4a8c8a547fca37e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}