{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Categorical embedding"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import tensorflow as tf\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from sklearn.preprocessing import OneHotEncoder\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, plot_confusion_matrix\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from keras import metrics\r\n",
    "from keras.models import Model\r\n",
    "from keras.layers import Dense, Dropout, Input, Embedding,Reshape, Concatenate\r\n",
    "from itertools import chain"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "data = pd.read_csv(\"./data/full_RASFF_DATA.csv\", sep=\";\", header=0, index_col=0)\r\n",
    "\r\n",
    "data.head(3)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLASSIF</th>\n",
       "      <th>DATE_CASE</th>\n",
       "      <th>REF</th>\n",
       "      <th>NOT_COUNTRY</th>\n",
       "      <th>SUBJET</th>\n",
       "      <th>PROD_CAT</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>RISK_DECISION</th>\n",
       "      <th>ACTION_TAKEN</th>\n",
       "      <th>DISTRIBUTION_STAT</th>\n",
       "      <th>PRODUCT</th>\n",
       "      <th>HAZARDS</th>\n",
       "      <th>HAZARDS_CAT</th>\n",
       "      <th>COUNT_ORIGEN</th>\n",
       "      <th>COUNT_DESTIN</th>\n",
       "      <th>COUNT_CONCERN</th>\n",
       "      <th>NUMBER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alert</td>\n",
       "      <td>2020-10-16</td>\n",
       "      <td>2020.4364</td>\n",
       "      <td>France</td>\n",
       "      <td>Listeria monocytogenes (presence) in ham trimm...</td>\n",
       "      <td>meat and meat products (other than poultry)</td>\n",
       "      <td>food</td>\n",
       "      <td>serious</td>\n",
       "      <td>recall from consumers</td>\n",
       "      <td>distribution to other member countries</td>\n",
       "      <td>ham trimmings</td>\n",
       "      <td>listeria monocytogenes</td>\n",
       "      <td>microbial contaminants (other)</td>\n",
       "      <td>France</td>\n",
       "      <td>Czech Republic,United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>border rejection</td>\n",
       "      <td>2020-10-16</td>\n",
       "      <td>2020.4349</td>\n",
       "      <td>Bulgaria</td>\n",
       "      <td>prochloraz (0.696 mg/kg - ppm) in mandarins fr...</td>\n",
       "      <td>fruits and vegetables</td>\n",
       "      <td>food</td>\n",
       "      <td>serious</td>\n",
       "      <td>destruction</td>\n",
       "      <td>product not (yet) placed on the market</td>\n",
       "      <td>mandarins</td>\n",
       "      <td>prochloraz</td>\n",
       "      <td>pesticide residues</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bulgaria</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>border rejection</td>\n",
       "      <td>2020-10-16</td>\n",
       "      <td>2020.4350</td>\n",
       "      <td>Bulgaria</td>\n",
       "      <td>fenvalerate (0.357 mg/kg - ppm) in chilled man...</td>\n",
       "      <td>fruits and vegetables</td>\n",
       "      <td>food</td>\n",
       "      <td>serious</td>\n",
       "      <td>re-dispatch</td>\n",
       "      <td>product not (yet) placed on the market</td>\n",
       "      <td>chilled mandarins</td>\n",
       "      <td>fenvalerate</td>\n",
       "      <td>pesticide residues</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bulgaria</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            CLASSIF   DATE_CASE        REF NOT_COUNTRY  \\\n",
       "0             alert  2020-10-16  2020.4364      France   \n",
       "1  border rejection  2020-10-16  2020.4349    Bulgaria   \n",
       "2  border rejection  2020-10-16  2020.4350    Bulgaria   \n",
       "\n",
       "                                              SUBJET  \\\n",
       "0  Listeria monocytogenes (presence) in ham trimm...   \n",
       "1  prochloraz (0.696 mg/kg - ppm) in mandarins fr...   \n",
       "2  fenvalerate (0.357 mg/kg - ppm) in chilled man...   \n",
       "\n",
       "                                      PROD_CAT  TYPE RISK_DECISION  \\\n",
       "0  meat and meat products (other than poultry)  food       serious   \n",
       "1                        fruits and vegetables  food       serious   \n",
       "2                        fruits and vegetables  food       serious   \n",
       "\n",
       "            ACTION_TAKEN                       DISTRIBUTION_STAT  \\\n",
       "0  recall from consumers  distribution to other member countries   \n",
       "1            destruction  product not (yet) placed on the market   \n",
       "2            re-dispatch  product not (yet) placed on the market   \n",
       "\n",
       "             PRODUCT                 HAZARDS                     HAZARDS_CAT  \\\n",
       "0      ham trimmings  listeria monocytogenes  microbial contaminants (other)   \n",
       "1          mandarins              prochloraz              pesticide residues   \n",
       "2  chilled mandarins             fenvalerate              pesticide residues   \n",
       "\n",
       "  COUNT_ORIGEN                   COUNT_DESTIN COUNT_CONCERN  NUMBER  \n",
       "0       France  Czech Republic,United Kingdom           NaN     NaN  \n",
       "1       Turkey                            NaN      Bulgaria     NaN  \n",
       "2       Turkey                            NaN      Bulgaria     NaN  "
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Basic pre-processing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "data.DATE_CASE = data.DATE_CASE.astype(str)\r\n",
    "data.HAZARDS_CAT = data.HAZARDS_CAT.astype(str)\r\n",
    "data.COUNT_DESTIN = data.COUNT_DESTIN.astype(str)\r\n",
    "data.COUNT_CONCERN = data.COUNT_CONCERN.astype(str)\r\n",
    "\r\n",
    "data.dropna(subset=data.columns[[1, 3, 5, 8, 9, 12, 13]], inplace=True)\r\n",
    "\r\n",
    "data = data.sample(frac=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def chainer(s):\r\n",
    "    return list(chain.from_iterable(s.str.split(',')))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "lens = data['HAZARDS_CAT'].str.split(',').map(len)\r\n",
    "split1 = pd.DataFrame({'DATE_CASE': np.repeat(data['DATE_CASE'], lens),\r\n",
    "                    'NOT_COUNTRY': np.repeat(data['NOT_COUNTRY'], lens),\r\n",
    "                    'PROD_CAT': np.repeat(data['PROD_CAT'], lens),\r\n",
    "                    'TYPE': np.repeat(data['TYPE'], lens),\r\n",
    "                    'RISK_DECISION': np.repeat(data['RISK_DECISION'], lens),\r\n",
    "                    'ACTION_TAKEN': np.repeat(data['ACTION_TAKEN'], lens),\r\n",
    "                    'DISTRIBUTION_STAT': np.repeat(data['DISTRIBUTION_STAT'], lens),\r\n",
    "                    'HAZARDS_CAT': chainer(data['HAZARDS_CAT']),\r\n",
    "                    'COUNT_ORIGEN': np.repeat(data['COUNT_ORIGEN'], lens),\r\n",
    "                    'COUNT_DESTIN': np.repeat(data['COUNT_DESTIN'], lens),\r\n",
    "                    'COUNT_CONCERN': np.repeat(data['COUNT_CONCERN'], lens)})\r\n",
    "\r\n",
    "lens = split1['COUNT_ORIGEN'].str.split(',').map(len)\r\n",
    "split2 = pd.DataFrame({'DATE_CASE': np.repeat(split1['DATE_CASE'], lens),\r\n",
    "                    'NOT_COUNTRY': np.repeat(split1['NOT_COUNTRY'], lens),\r\n",
    "                    'PROD_CAT': np.repeat(split1['PROD_CAT'], lens),\r\n",
    "                    'TYPE': np.repeat(split1['TYPE'], lens),\r\n",
    "                    'RISK_DECISION': np.repeat(split1['RISK_DECISION'], lens),\r\n",
    "                    'ACTION_TAKEN': np.repeat(split1['ACTION_TAKEN'], lens),\r\n",
    "                    'DISTRIBUTION_STAT': np.repeat(split1['DISTRIBUTION_STAT'], lens),\r\n",
    "                    'HAZARDS_CAT': np.repeat(split1['HAZARDS_CAT'], lens),\r\n",
    "                    'COUNT_ORIGEN': chainer(split1['COUNT_ORIGEN']),\r\n",
    "                    'COUNT_DESTIN': np.repeat(split1['COUNT_DESTIN'], lens),\r\n",
    "                    'COUNT_CONCERN': np.repeat(split1['COUNT_CONCERN'], lens)})\r\n",
    "\r\n",
    "lens = split2['COUNT_DESTIN'].str.split(',').map(len)\r\n",
    "split3 = pd.DataFrame({'DATE_CASE': np.repeat(split2['DATE_CASE'], lens),\r\n",
    "                    'NOT_COUNTRY': np.repeat(split2['NOT_COUNTRY'], lens),\r\n",
    "                    'PROD_CAT': np.repeat(split2['PROD_CAT'], lens),\r\n",
    "                    'TYPE': np.repeat(split2['TYPE'], lens),\r\n",
    "                    'RISK_DECISION': np.repeat(split2['RISK_DECISION'], lens),\r\n",
    "                    'ACTION_TAKEN': np.repeat(split2['ACTION_TAKEN'], lens),\r\n",
    "                    'DISTRIBUTION_STAT': np.repeat(split2['DISTRIBUTION_STAT'], lens),\r\n",
    "                    'HAZARDS_CAT': np.repeat(split2['HAZARDS_CAT'], lens),\r\n",
    "                    'COUNT_ORIGEN': np.repeat(split2['COUNT_ORIGEN'], lens),\r\n",
    "                    'COUNT_DESTIN': chainer(split2['COUNT_DESTIN']),\r\n",
    "                    'COUNT_CONCERN': np.repeat(split2['COUNT_CONCERN'], lens)})\r\n",
    "\r\n",
    "lens = split3['COUNT_CONCERN'].str.split(',').map(len)\r\n",
    "split4 = pd.DataFrame({'DATE_CASE': np.repeat(split3['DATE_CASE'], lens),\r\n",
    "                    'NOT_COUNTRY': np.repeat(split3['NOT_COUNTRY'], lens),\r\n",
    "                    'PROD_CAT': np.repeat(split3['PROD_CAT'], lens),\r\n",
    "                    'TYPE': np.repeat(split3['TYPE'], lens),\r\n",
    "                    'RISK_DECISION': np.repeat(split3['RISK_DECISION'], lens),\r\n",
    "                    'ACTION_TAKEN': np.repeat(split3['ACTION_TAKEN'], lens),\r\n",
    "                    'DISTRIBUTION_STAT': np.repeat(split3['DISTRIBUTION_STAT'], lens),\r\n",
    "                    'HAZARDS_CAT': np.repeat(split3['HAZARDS_CAT'], lens),\r\n",
    "                    'COUNT_ORIGEN': np.repeat(split3['COUNT_ORIGEN'], lens),\r\n",
    "                    'COUNT_DESTIN': np.repeat(split3['COUNT_DESTIN'], lens),\r\n",
    "                    'COUNT_CONCERN': chainer(split3['COUNT_CONCERN'])})\r\n",
    "\r\n",
    "split4 = split4.reset_index(drop = True)\r\n",
    "split4 = split4.dropna(subset = ['DATE_CASE'])\r\n",
    "\r\n",
    "data = split4.copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "data.head(3)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE_CASE</th>\n",
       "      <th>NOT_COUNTRY</th>\n",
       "      <th>PROD_CAT</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>RISK_DECISION</th>\n",
       "      <th>ACTION_TAKEN</th>\n",
       "      <th>DISTRIBUTION_STAT</th>\n",
       "      <th>HAZARDS_CAT</th>\n",
       "      <th>COUNT_ORIGEN</th>\n",
       "      <th>COUNT_DESTIN</th>\n",
       "      <th>COUNT_CONCERN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-06-18</td>\n",
       "      <td>Italy</td>\n",
       "      <td>fruits and vegetables</td>\n",
       "      <td>food</td>\n",
       "      <td>undecided</td>\n",
       "      <td>re-dispatch</td>\n",
       "      <td></td>\n",
       "      <td>food additives and flavourings</td>\n",
       "      <td>Syria</td>\n",
       "      <td></td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-06-18</td>\n",
       "      <td>Italy</td>\n",
       "      <td>fruits and vegetables</td>\n",
       "      <td>food</td>\n",
       "      <td>undecided</td>\n",
       "      <td>re-dispatch</td>\n",
       "      <td></td>\n",
       "      <td>food additives and flavourings</td>\n",
       "      <td>Syria</td>\n",
       "      <td></td>\n",
       "      <td>Spain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-14</td>\n",
       "      <td>Finland</td>\n",
       "      <td>other food product / mixed</td>\n",
       "      <td>food</td>\n",
       "      <td>undecided</td>\n",
       "      <td>recall from consumers</td>\n",
       "      <td>distribution restricted to notifying country</td>\n",
       "      <td>mycotoxins</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Finland</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DATE_CASE NOT_COUNTRY                    PROD_CAT  TYPE RISK_DECISION  \\\n",
       "0  2003-06-18       Italy       fruits and vegetables  food     undecided   \n",
       "1  2003-06-18       Italy       fruits and vegetables  food     undecided   \n",
       "2  2019-11-14     Finland  other food product / mixed  food     undecided   \n",
       "\n",
       "            ACTION_TAKEN                             DISTRIBUTION_STAT  \\\n",
       "0            re-dispatch                                                 \n",
       "1            re-dispatch                                                 \n",
       "2  recall from consumers  distribution restricted to notifying country   \n",
       "\n",
       "                      HAZARDS_CAT    COUNT_ORIGEN COUNT_DESTIN COUNT_CONCERN  \n",
       "0  food additives and flavourings           Syria                      Italy  \n",
       "1  food additives and flavourings           Syria                      Spain  \n",
       "2                      mycotoxins  United Kingdom      Finland           nan  "
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Features selection"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "categorical_vars = [0, 1, 6, 8]\r\n",
    "target_vars = [2]\r\n",
    "\r\n",
    "X = data.iloc[:, categorical_vars]\r\n",
    "Y = data.iloc[:, target_vars]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "ency = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\r\n",
    "\r\n",
    "ency.fit(Y.values)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OneHotEncoder(handle_unknown='ignore', sparse=False)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split train-val-test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# x_training_data, x_test_data, y_training_data, y_test_data = train_test_split(X, y_one_hot, test_size=0.2, random_state=42, shuffle=True)\r\n",
    "\r\n",
    "train_mask = (data.DATE_CASE >= \"2004-01-01\") & (data.DATE_CASE <= \"2018-12-31\")\r\n",
    "test_mask = (data.DATE_CASE >= \"2019-01-01\") & (data.DATE_CASE <= \"2019-12-31\")\r\n",
    "\r\n",
    "x_training_data = X.loc[train_mask]\r\n",
    "y_training_data = Y.loc[train_mask]\r\n",
    "x_test_data = X.loc[test_mask]\r\n",
    "y_test_data = Y.loc[test_mask]\r\n",
    "\r\n",
    "x_training_data = ency.transform(x_training_data.values)\r\n",
    "x_test_data = ency.transform(x_test_data.values)\r\n",
    "\r\n",
    "x_training_data, x_val_data, y_training_data, y_val_data = train_test_split(x_training_data, y_training_data, test_size=0.2, random_state=42, shuffle=True)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "The number of features in X is different to the number of features of the fitted data. The fitted data had 1 features and the X has 4 features.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17396/1201637624.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0my_test_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mx_training_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mency\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_training_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mx_test_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mency\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\ceiec\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m         \u001b[1;31m# validation of X happens in _check_X called by _transform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 471\u001b[1;33m         X_int, X_mask = self._transform(X, handle_unknown=self.handle_unknown,\n\u001b[0m\u001b[0;32m    472\u001b[0m                                         force_all_finite='allow-nan')\n\u001b[0;32m    473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\ceiec\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36m_transform\u001b[1;34m(self, X, handle_unknown, force_all_finite)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategories_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    121\u001b[0m                 \u001b[1;34m\"The number of features in X is different to the number of \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m                 \u001b[1;34m\"features of the fitted data. The fitted data had {} features \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The number of features in X is different to the number of features of the fitted data. The fitted data had 1 features and the X has 4 features."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Coding and conversion to lists for beign able to introduce it into the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "categorical_vars = data.iloc[:, categorical_vars].columns\r\n",
    "\r\n",
    "def preproc(X_train, X_test, X_val):\r\n",
    "    input_list_train = []\r\n",
    "    input_list_test = []\r\n",
    "    input_list_testval = []\r\n",
    "    \r\n",
    "    for c in categorical_vars:\r\n",
    "        raw_vals = np.unique(X_train[c])\r\n",
    "        val_map = {}\r\n",
    "        for i in range(len(raw_vals)):\r\n",
    "            val_map[raw_vals[i]] = i       \r\n",
    "        \r\n",
    "        input_list_train.append(X_train[c].map(val_map).values)\r\n",
    "        input_list_test.append(X_test[c].map(val_map).fillna(0).values)\r\n",
    "        input_list_testval.append(X_val[c].map(val_map).fillna(0).values)\r\n",
    "\r\n",
    "    return input_list_train, input_list_test,input_list_testval"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "input_list_train, input_list_test, input_list_testval = preproc(x_training_data, x_test_data, x_val_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Metrics definition"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def top_1_categorical_accuracy(y_true, y_pred):\r\n",
    "\treturn metrics.top_k_categorical_accuracy(y_true, y_pred, k=1)\r\n",
    "\r\n",
    "def top_2_categorical_accuracy(y_true, y_pred):\r\n",
    "    return metrics.top_k_categorical_accuracy(y_true, y_pred, k=2)\r\n",
    "\r\n",
    "def top_3_categorical_accuracy(y_true, y_pred):\r\n",
    "    return metrics.top_k_categorical_accuracy(y_true, y_pred, k=3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Embeddings + MLP Models (cases 1 and 3)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "input_models = []\r\n",
    "output_embeddings = []\r\n",
    "\r\n",
    "for categorical_var in categorical_vars:\r\n",
    "    cat_emb_name = categorical_var.replace(\" \", \"\") + \"_Embedding\"\r\n",
    "    input_name = \"Input_\" + categorical_var.replace(\" \", \"\")\r\n",
    "    no_of_unique_cat = x_training_data[categorical_var].nunique()\r\n",
    "    embedding_size = int(min(np.ceil((no_of_unique_cat)/2), 50))\r\n",
    "   \r\n",
    "    input_model = Input(shape=(1, ), name=input_name)\r\n",
    "    output_model = Embedding(no_of_unique_cat, embedding_size, name=cat_emb_name)(input_model)\r\n",
    "    output_model = Reshape(target_shape=(embedding_size, ))(output_model)    \r\n",
    "    \r\n",
    "    input_models.append(input_model)\r\n",
    "    output_embeddings.append(output_model)\r\n",
    "  \r\n",
    "output = Concatenate()(output_embeddings)\r\n",
    "output = Dense(2048,activation=\"relu\")(output)\r\n",
    "output = Dropout(0.3)(output)\r\n",
    "output = Dense(1024,activation=\"relu\")(output)\r\n",
    "output = Dropout(0.2)(output)\r\n",
    "output = Dense(512,activation=\"relu\")(output)\r\n",
    "output = Dropout(0.2)(output)\r\n",
    "output = Dense(42, activation=\"softmax\")(output)\r\n",
    "\r\n",
    "model = Model(inputs=input_models, outputs=output)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\", top_1_categorical_accuracy,top_2_categorical_accuracy,top_3_categorical_accuracy])\r\n",
    "\r\n",
    "model.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# REVIEW: No validation data has been provided\r\n",
    " \r\n",
    "# hist = model.fit(input_list_train, y_training_data, validation_data=(input_list_test, y_test_data), epochs=5 , batch_size=64, verbose=1)\r\n",
    "hist = model.fit(input_list_train, y_training_data, validation_data=(input_list_testval, y_val_data), epochs=5, batch_size=64, verbose=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_metrics():\r\n",
    "\tresult = model.predict(input_list_test, batch_size=64)\r\n",
    "\tresult = np.argmax(result, axis=-1)\r\n",
    "\r\n",
    "\tvalid_loss, valid_accuracy, acc1, acc2, acc3 = model.evaluate(input_list_test)\r\n",
    "\r\n",
    "\tprint(\"Loss:\", valid_loss)\r\n",
    "\tprint(\"Accuracy:\", valid_accuracy)\r\n",
    "\tprint(\"Top-1 Accuracy:\", acc1)\r\n",
    "\tprint(\"Top-2 Accuracy:\", acc2)\r\n",
    "\tprint(\"Top-3 Accuracy:\", acc3)\r\n",
    "\r\n",
    "\tprint(classification_report(np.argmax(y_test_data, axis=-1), result, zero_division=True))\r\n",
    "\r\n",
    "\tcm = confusion_matrix(np.argmax(y_test_data, axis=-1), result)\r\n",
    "\tcm = ConfusionMatrixDisplay(confusion_matrix=cm)\r\n",
    "\r\n",
    "\tfig, ax = plt.subplots(figsize=(20, 20))\r\n",
    "\tcm.plot(ax=ax)\r\n",
    "\r\n",
    "\tplt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "get_metrics()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# result = model.predict(input_list_test, batch_size=64)\r\n",
    "# result = np.argmax(result, axis=1)\r\n",
    "\r\n",
    "# valid_loss, valid_accuracy, acc1, acc2, acc3 = model.evaluate(input_list_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# print(\"Loss:\", valid_loss)\r\n",
    "# print(\"Accuracy:\", valid_accuracy)\r\n",
    "# print(\"Top-1 Accuracy:\", acc1)\r\n",
    "# print(\"Top-2 Accuracy:\", acc2)\r\n",
    "# print(\"Top-3 Accuracy:\", acc3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# print(classification_report(np.argmax(y_test_data, axis=-1), result, zero_division=True))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# cm = confusion_matrix(np.argmax(y_test_data, axis=-1), result)\r\n",
    "# cm = ConfusionMatrixDisplay(confusion_matrix=cm)\r\n",
    "\r\n",
    "# fig, ax = plt.subplots(figsize=(20, 20))\r\n",
    "# cm.plot(ax=ax)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "N = 5\r\n",
    "\r\n",
    "plt.style.use(\"ggplot\")\r\n",
    "\r\n",
    "plt.figure()\r\n",
    "\r\n",
    "plt.plot(np.arange(0, N), hist.history[\"loss\"], label=\"train_loss\")\r\n",
    "plt.plot(np.arange(0, N), hist.history[\"val_loss\"], label=\"val_loss\")\r\n",
    "plt.plot(np.arange(0, N), hist.history[\"accuracy\"], label=\"train_acc\")\r\n",
    "plt.plot(np.arange(0, N), hist.history[\"val_accuracy\"], label=\"val_acc\")\r\n",
    "\r\n",
    "plt.title(\"Training Loss and Accuracy\")\r\n",
    "plt.xlabel(\"Epoch #\")\r\n",
    "plt.ylabel(\"Loss/Accuracy\")\r\n",
    "plt.legend(loc=\"lower left\")\r\n",
    "\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "historials = []\r\n",
    "evaluations = []\r\n",
    "\r\n",
    "for i in range (1, 6):\r\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\", top_1_categorical_accuracy, top_2_categorical_accuracy, top_3_categorical_accuracy])\r\n",
    "    \r\n",
    "    hist = model.fit(input_list_train, y_training_data, validation_data=(input_list_testval, y_val_data), epochs=25, batch_size=64, verbose=0)\r\n",
    "    historials.append(hist)\r\n",
    "    \r\n",
    "    evaluation = model.evaluate(x=input_list_test, y=y_test_data)\r\n",
    "    evaluations.append(evaluation)\r\n",
    "    \r\n",
    "    model.save(\"model\" + str(i) + \".h5\")\r\n",
    "\r\n",
    "    get_metrics()\r\n",
    "\r\n",
    "    print(\"\\n\\n-----------------------\\n\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('ceiec': conda)"
  },
  "interpreter": {
   "hash": "d98ed641ffb0afae769cd9f96943c7d5fe6ff4d949b5ee86e4a8c8a547fca37e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}